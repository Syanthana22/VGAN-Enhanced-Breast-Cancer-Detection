{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uunh8iholDs"
      },
      "source": [
        "## Loading and Preprocessing Dataset\n",
        "Intially Loaded the Dataset.\n",
        "# Preprocessing the Dataset\n",
        "Initially applied resizing technique.Then applied Cropping of images and then applied Min-Max Normalization to the above cropped Images.\n",
        "After applying the normalization technique on cropped images,we then saved the images in a folder named preprocessed images\n",
        "This is the link of Preprocessed images\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "https://drive.google.com/drive/folders/1GHjda1zgsK0K67QMTJM3FIW62tUvXE8c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fu4FBa-3uew",
        "outputId": "cab84c4b-7dbe-4a1d-d735-dfa0780f6de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWgj6XePSSzU",
        "outputId": "f9eb15a5-4df8-4e26-853c-dada02df13f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images: 100\n",
            "Shape of resized images array: (100, 64, 64, 3)\n",
            "Shape of cropped images array: (100, 60, 60, 3)\n",
            "Normalized and cropped images shape: (100, 60, 60, 3)\n",
            "Preprocessed images saved in folder: /content/drive/MyDrive/Project3/PreprocessedImages\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "def load_dataset(folder_path):\n",
        "    images = []\n",
        "\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        if image_file.endswith('.jpg') or image_file.endswith('.png'):  # Add additional formats if needed\n",
        "            images.append(image_file)\n",
        "    return images\n",
        "folder_path = \"/content/drive/MyDrive/Final Year Project/Dataset1\"\n",
        "images = load_dataset(folder_path)\n",
        "print(\"Number of images:\", len(images))\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "def resize_dataset(folder_path, target_size=(64, 64)):\n",
        "    resized_images = []\n",
        "\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        if image_file.endswith('.jpg') or image_file.endswith('.png'):  # Add additional formats if needed\n",
        "            # Load image using PIL and resize\n",
        "            image = Image.open(image_path)\n",
        "            resized_image = image.resize(target_size)\n",
        "            # Convert image to numpy array and normalize pixel values\n",
        "            resized_image_array = np.array(resized_image) / 255.0\n",
        "            resized_images.append(resized_image_array)\n",
        "    return resized_images\n",
        "folder_path = \"/content/drive/MyDrive/Final Year Project/Dataset1\"\n",
        "resized_images = resize_dataset(folder_path)\n",
        "resized_images_array = np.array(resized_images)\n",
        "print(\"Shape of resized images array:\", resized_images_array.shape)\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "def resize_and_crop_dataset(folder_path, target_size=(64, 64), crop_size=(60, 60)):\n",
        "    cropped_images = []\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        if image_file.endswith('.jpg') or image_file.endswith('.png'):  # Add additional formats if needed\n",
        "            # Load image using PIL and resize\n",
        "            image = Image.open(image_path)\n",
        "            image = image.resize(target_size)\n",
        "            # Crop image\n",
        "            width, height = image.size\n",
        "            left = (width - crop_size[0]) // 2\n",
        "            top = (height - crop_size[1]) // 2\n",
        "            right = left + crop_size[0]\n",
        "            bottom = top + crop_size[1]\n",
        "            cropped_image = image.crop((left, top, right, bottom))\n",
        "            # Convert cropped image to numpy array and normalize pixel values\n",
        "            cropped_image_array = np.array(cropped_image) / 255.0\n",
        "            cropped_images.append(cropped_image_array)\n",
        "    return cropped_images\n",
        "folder_path = \"//content/drive/MyDrive/Final Year Project/Dataset1\"\n",
        "cropped_images = resize_and_crop_dataset(folder_path)\n",
        "cropped_images_array = np.array(cropped_images)\n",
        "print(\"Shape of cropped images array:\", cropped_images_array.shape)\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def resize_and_crop_dataset(folder_path, target_size=(64, 64), crop_size=(60, 60)):\n",
        "    cropped_images = []\n",
        "\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        try:\n",
        "            if image_file.endswith('.jpg') or image_file.endswith('.png'):\n",
        "                image = Image.open(image_path)  # Remove .convert('L') to keep the image in color\n",
        "                # Resize image to the target size\n",
        "                resized_image = image.resize(target_size)\n",
        "                # Crop image\n",
        "                width, height = resized_image.size\n",
        "                left = (width - crop_size[0]) // 2\n",
        "                top = (height - crop_size[1]) // 2\n",
        "                right = left + crop_size[0]\n",
        "                bottom = top + crop_size[1]\n",
        "                cropped_image = resized_image.crop((left, top, right, bottom))\n",
        "                # Convert cropped image to numpy array and normalize pixel values\n",
        "                cropped_image_array = np.array(cropped_image) / 255.0\n",
        "                cropped_images.append(cropped_image_array)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image: {image_path}, Error: {e}\")\n",
        "\n",
        "    normalized_cropped_images = np.array(cropped_images)\n",
        "    return normalized_cropped_images\n",
        "\n",
        "\n",
        "    normalized_cropped_images = np.array(cropped_images)\n",
        "    normalized_cropped_images_expanded = np.expand_dims(normalized_cropped_images, axis=-1)\n",
        "    return normalized_cropped_images_expanded\n",
        "\n",
        "# Load and preprocess the dataset with adjusted target_size\n",
        "folder_path = \"/content/drive/MyDrive/Final Year Project/Dataset1\"\n",
        "normalized_cropped_images = resize_and_crop_dataset(folder_path, target_size=(64, 64))\n",
        "\n",
        "print(\"Normalized and cropped images shape:\", normalized_cropped_images.shape)\n",
        "\n",
        "\n",
        "# Now you can save the preprocessed images if needed\n",
        "output_folder = \"/content/drive/MyDrive/Project3/PreprocessedImages\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for i, image in enumerate(normalized_cropped_images):\n",
        "    processed_image = Image.fromarray((image * 255).astype(np.uint8))\n",
        "    processed_image.save(os.path.join(output_folder, f\"preprocessed_image_{i}.png\"))\n",
        "\n",
        "print(\"Preprocessed images saved in folder:\", output_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9hSYmMOTvvI"
      },
      "source": [
        "## Tissue Segmentation\n",
        "\n",
        "We applied tissue segmentation as we are taking MRI images in the dataset which is helpful to calculate the tumor and identiy the tissue thickness in the taken image.\n",
        "\n",
        "\n",
        "After applying tissue segmentation on the preprocessed images,those images are saved in the folder as segmented_images.\n",
        "Link to access Segmented Images\n",
        "\n",
        "https://drive.google.com/drive/folders/152njGcXXWCxsuUzQI1w00DZbP4VkzHXq?usp=drive_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKnzRpFRpJaK",
        "outputId": "9e1bedb1-cbb4-49c1-da02-902f44042923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized and cropped images shape: (100, 60, 60, 3)\n",
            "Segmented images saved in folder: /content/drive/MyDrive/Project3/SegmentedImages\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def segment_tissue(image):\n",
        "    # Convert the image to grayscale\n",
        "    grayscale_image = np.array(image.convert(\"L\"))\n",
        "\n",
        "    # Apply a simple thresholding technique to segment tissue\n",
        "    threshold = 100\n",
        "    tissue_mask = grayscale_image > threshold\n",
        "\n",
        "    return tissue_mask\n",
        "\n",
        "def resize_and_crop_dataset(folder_path, target_size=(64, 64), crop_size=(60, 60)):\n",
        "    cropped_images = []\n",
        "\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        try:\n",
        "            if image_file.endswith('.jpg') or image_file.endswith('.png'):\n",
        "                image = Image.open(image_path)  # Remove .convert('L') to keep the image in color\n",
        "                # Resize image to the target size\n",
        "                resized_image = image.resize(target_size)\n",
        "                # Crop image\n",
        "                width, height = resized_image.size\n",
        "                left = (width - crop_size[0]) // 2\n",
        "                top = (height - crop_size[1]) // 2\n",
        "                right = left + crop_size[0]\n",
        "                bottom = top + crop_size[1]\n",
        "                cropped_image = resized_image.crop((left, top, right, bottom))\n",
        "\n",
        "                # Perform tissue segmentation\n",
        "                tissue_mask = segment_tissue(cropped_image)\n",
        "\n",
        "                # Apply the tissue mask to the cropped image\n",
        "                segmented_image = np.array(cropped_image) * tissue_mask[:, :, np.newaxis]\n",
        "\n",
        "                # Normalize pixel values\n",
        "                segmented_image = segmented_image / 255.0\n",
        "\n",
        "                cropped_images.append(segmented_image)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image: {image_path}, Error: {e}\")\n",
        "\n",
        "    normalized_cropped_images = np.array(cropped_images)\n",
        "    return normalized_cropped_images\n",
        "\n",
        "# Load and preprocess the dataset with adjusted target_size\n",
        "folder_path = \"/content/drive/MyDrive/Project3/PreprocessedImages\"\n",
        "normalized_cropped_images = resize_and_crop_dataset(folder_path, target_size=(64, 64))\n",
        "\n",
        "print(\"Normalized and cropped images shape:\", normalized_cropped_images.shape)\n",
        "\n",
        "# Now you can save the segmented images in a folder\n",
        "output_folder = \"/content/drive/MyDrive/Project3/SegmentedImages\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for i, image in enumerate(normalized_cropped_images):\n",
        "    segmented_image = Image.fromarray((image * 255).astype(np.uint8))\n",
        "    segmented_image.save(os.path.join(output_folder, f\"segmented_image_{i}.png\"))\n",
        "\n",
        "print(\"Segmented images saved in folder:\", output_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCeu4TR1U62c"
      },
      "source": [
        "#### From the segmented images dataset we printed randomly of 3 images in view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l_2cIWQUqpAa",
        "outputId": "e79035db-3c72-40de-9c74-6db9f9c1a3a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Image 1:\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAOwUlEQVR4nO3dPW8dVRcF4IntOBYpEP+B4u2pkGioaPltUNHQpQXR0FAARQBRpEdISAjxlQiiiIQ4vg55uyUUnT3MHo9NsJ+nPPfembnXUpaOWOxz7dmzZ88mAJimae/ffgAAXhxCAYAQCgCEUAAghAIAIRQACKEAQAgFAOJg6Rs//PDD4fre3jhXrl271n6Yv/76a7j+4MGD4frdu3eH648fPx6uHxyMv+7c/79XPdPTp09b67vdbrh+eno6XD86Oiqf6Z133hmu//HHH+VnAJb8v8p2CgCEUAAghAIAIRQACKEAQCxuH1X/1bpaX9M+6l5rf3+/df2qSbTmWbuq71Z9h7nvdhHPC1xNdgoAhFAAIIQCACEUAAihAEAsbh9tZW72RrfhVOm2c+auv9W1tmxpAZwXOwUAQigAEEIBgBAKAIRQACAWt4+2auFU84emqT61rNvo2bKttFVrqHr/mt+p+/0AlrJTACCEAgAhFAAIoQBACAUAQigAEIsrqXt7vfxYU7WsXuuub1nZnHvekep3qiqp3e8GcJ7sFAAIoQBACAUAQigAEEIBgDi34zjXDKurBuJt1cS5iEFy3fZRZe5ZT05OWtcCWMpOAYAQCgCEUAAghAIAIRQAiDO3j6pm0Onp6XC9ahjNXas746hq+nSPxJzTvUdlTUvrtddeG67fuXNnuH58fNx6JuDqslMAIIQCACEUAAihAEAIBQBicfuo2wBac/Ja1UzqzkSq7t09PW6a+m2iylYnsk3TNL3xxhvD9W+++Wa4rn0ELGWnAEAIBQBCKAAQQgGAEAoAxLm1j9aoWka73a71/m4jaq5h1J2XtNWcpjnVXKmLOFkOuNzsFAAIoQBACAUAQigAEEIBgFjcPlpzQlhX1SY6OTlpvb+y5rS0qk3UbSV1f6e59+/v77euBbCUnQIAIRQACKEAQAgFAEIoABBCAYBYXEmtdAe9zVUtq0Fv3cF3lW699J9e2+Iea44OPTgY/9m2OjoUuLrsFAAIoQBACAUAQigAEEIBgFjcPuo2W6rGUNUwmqa6udN9prnmTuc6c9eqvt9Wx3GuGYinfQSclZ0CACEUAAihAEAIBQBCKAAQi9tHVQunatt016epbvRU69UzdY+rnGv6dBs91b27raQ51ffWPgLOyk4BgBAKAIRQACCEAgAhFACIxe2jbpuoatXMzT7a7Xate1SqFk51YtlcA+jJkyetZ+qevFatz/1OWkbAebFTACCEAgAhFAAIoQBACAUAYnH7qGroVOtrZh9V1+qeNNY9eW1Oda3u9+7+fmtOgwM4K/+6ABBCAYAQCgCEUAAghAIAceaT16r2THVa2txMn7nXRqpZRl1zbZ6q+VR9v+6Mo8rcPCYnrwHnxU4BgBAKAIRQACCEAgAhFAAIoQBALO50diuY1fuPj483u0c1fG7LAXrVM3UH2W1ZI52rqwKchZ0CACEUAAihAEAIBQBCKAAQi9tH3WMmT05Ohuu73a68R/c4zkr1rGuOsazuXQ3jq4b6Vfde80zdoz0BlrJTACCEAgAhFAAIoQBACAUAYnH7qJrRU7VtqpbRmmMm1zR0RtYclblmXtJI1Yhao3qmqvEFsJSdAgAhFAAIoQBACAUAQigAEIvbR5WqZVS1ktY0fbqnk3WvM9eI6s4T6t57Tbup+s3feuut4fonn3wyXL9//355D+BqslMAIIQCACEUAAihAEAIBQBicfuoe8Ja1T5aM/uoa6sW05zunKZqfc1pc0+fPh2u/+9//xuu3759e7iufQQ8z04BgBAKAIRQACCEAgAhFACIxe2jqvGypmVU2bIdNFI909x951pAnXt01+eaWNUpbtevXx+un/fvClwedgoAhFAAIIQCACEUAAihAEAIBQBicSW1OgKyqqquOWay6yKOvuxWRqsKa/U7de87d62qkrrlbw5cbv61ACCEAgAhFAAIoQBACAUAYnH76PHjx8P1aiBeZW7AXHeIXtUmqu5RtXDmBsZ1B/5Vw+q2+m5z11rz/QD+zk4BgBAKAIRQACCEAgAhFACIxe2j4+Pj4Xp3ps9cE6Zqz3SP0dxy7lK3ZdRtH615Vm0i4LzYKQAQQgGAEAoAhFAAIIQCALG4fVTNAOrO25lr1Zz3CWHdBtA01XOUqpZR90S2brtpmvrto25DDLi67BQACKEAQAgFAEIoABBCAYBY3D66iPlD3SZTtb6m0VOp7nFwsPinm32m7nebe2232w3XX3nlleH6r7/+2roOcPnZKQAQQgGAEAoAhFAAIIQCANGr0DSsafpUuieyVevVDKDq/XP3rq5VzYja8veoPHnyZLj+9ttvD9dv3bo1XP/uu++2eiTgP8ZOAYAQCgCEUAAghAIAIRQACKEAQFz4QLw1thqI112fe6078K9bSZ17pu73voi/EXA52CkAEEIBgBAKAIRQACCEAgCxuH3UbbxU5o7jrFTNnepa1VGZh4eHw/WTk5Py3t0hetV6d7DemuM4q3tXv8eavwVwuflXAYAQCgCEUAAghAIAIRQAiDMfx3kRM46qlkzVJnrppZeG6/v7+8P1R48elc90fHw8XK8aUVsdxzn3u3abTNX31j4CnudfBQBCKAAQQgGAEAoAhFAAIM48+6hqtqxRze6pWjXVzKKqlXT9+vXh+lwLZ7fbtdarZ63aR2tOg9vq5DWA59kpABBCAYAQCgCEUAAghAIAsbh9VM0T6jaGqvW5a3Vn9FRNn24zaE71TFu1jObaR93PVO0jrSTgeXYKAIRQACCEAgAhFAAIoQBALG4fVXODqpPJqibM3KykqtFTrR8cjB+/ukfVDNrylLNKd0bUmtlH1TwmLSNgKTsFAEIoABBCAYAQCgCEUAAghAIAsbiSWh19eXp6OlyvKpVVtXWa6tpmd6Bbd0jfXGXz6Ohok2t1B+XNqT7THeynqgo8z04BgBAKAIRQACCEAgAhFACIxe2jrY56nGvbVO2ZLYfJdVVtqaqV1G0+VeaaRN1rASxlpwBACAUAQigAEEIBgBAKAMS5tY+21L3HVk2pOdVRoFVbqWoMrZmJVL221TpwddkpABBCAYAQCgCEUAAghAIAceb2UbfBsqbpc95zl9Y0fSpVK+nw8LB1/epEu7nXqmt1T7QDri47BQBCKAAQQgGAEAoAhFAAIBa3j6qZPrvdbri+ZqbPVq2a6v1rnqnSPSWu+v2q61S/69xrVZuoakQ5wQ14np0CACEUAAihAEAIBQBCKAAQZ24fVc2dbitp7rVqfW9vnGlbnii21XylSvUdqsbQNNUNp+paVavr1VdfHa7/+OOPw/VHjx6VzwRcDnYKAIRQACCEAgAhFAAIoQBACAUAYnEltaqYdofVVbXJLc3VXkfWPFP3GM1q+NzJyclwfe6ozO5wvePj4+H666+/PlyvnvXrr78un+n+/fvla8B/h50CACEUAAihAEAIBQBCKAAQZ24fVS2jo6Oj1vunabtjNKv2TLW+ZoBe1TKqfqdqvWofVQ2jaarbUnOf6dz7zTffHK4/fPiwvNbt27db9wZeTHYKAIRQACCEAgAhFAAIoQBALG4f3bhxY7hetYkODw+H63MzfapGT7eVtNX6NPWbTN2WUXWduWeq2kdV4+uHH34Yrv/+++/D9epvZ74RXH52CgCEUAAghAIAIRQACKEAQCxuH1VzdaomTNW2qdanqW4fdWcfdc01orrzlar3V+vdWUnTNE03b94crld/iw8++GC4/vPPP5f3AK4mOwUAQigAEEIBgBAKAIRQACAWt4+qtk3VJqraM3MzfSpVq6bSbQCtcd73mPudqrbUTz/91L4WwN/ZKQAQQgGAEAoAhFAAIIQCALG4fVS1jKpmS/cUtTlzs4nOW9W6qnTnNFXNqrnGVXXC2q1bt4br9+7dK68F8Hd2CgCEUAAghAIAIRQACKEAQAgFAGJxJXXueMiONfXS7vC56h5r7t39TPf4zqq6e3BQ/2kePXrUujfAUnYKAIRQACCEAgAhFAAIoQBALG4fdRtA1WC4uTbPVoPvus8619qpWkPVencgXtU+evnll8tnevfdd4frv/32W/kZgCXsFAAIoQBACAUAQigAEEIBgDhz+6iy5YyjrXTnEs291l2vWkY3btwYrj948KB8pj///HO4bvYRcFZ2CgCEUAAghAIAIRQACKEAQCxuH+3tjfPjIlpJle7cpe763Gvd2UfVejXj6P333y+f6fHjx+VrAGdhpwBACAUAQigAEEIBgBAKAMTi9tH+/n7rwt0TyOY+U1lzklr3/dXMot1uN1yvWkk3b94crr/33nvD9V9++aV8JoDzYqcAQAgFAEIoABBCAYAQCgDE4vZR1arpzjJaczpYt2XUnVdUNYzmPlPd++Bg/JM+fPhwuP7999+X9wa4aHYKAIRQACCEAgAhFAAIoQBACAUAYnEltap5bllJ3ap62q2kVutz966OJ61+j48++qj1/jXVXYCzslMAIIQCACEUAAihAEAIBQDi3NpHa1o13eM4u+2jNUeEVseQVo2ljz/+eLj+7bfflvcAeFHYKQAQQgGAEAoAhFAAIIQCALG4ffRv6raJquM1q/dXR2hO0zQ9efJkuP7ZZ58N1+/cuVNeC+BFZ6cAQAgFAEIoABBCAYAQCgDEubWP1pwc1j3FrXuS2vXr14frx8fH5T1u3749XP/iiy/+4ekA/nvsFAAIoQBACAUAQigAEEIBgFjcPuo2g9a0j6rPdGcfHR4eDterltGXX35ZPtPnn39evgZw2dgpABBCAYAQCgCEUAAghAIAcW7to+r91VyiaarbRNVn9vbGmVa1jKp5RZ9++mn5TABXiZ0CACEUAAihAEAIBQBCKAAQQgGAOPNxnN2q6pzT09PhelVVPTo6Gq5/9dVXw3XVU4B5dgoAhFAAIIQCACEUAAihAECc20C8qkl0cnJSfqZqGVX3vnv37nD93r17//B0AIzYKQAQQgGAEAoAhFAAIIQCAHHt2bNnz/7thwDgxWCnAEAIBQBCKAAQQgGAEAoAhFAAIIQCACEUAAihAED8H6BFQW0BdLtOAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Image 2:\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Image 3:\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "def resize_and_crop_dataset(folder_path, target_size=(64, 64), crop_size=(60, 60)):\n",
        "    cropped_images = []\n",
        "\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        try:\n",
        "            if image_file.endswith('.jpg') or image_file.endswith('.png'):\n",
        "                image = Image.open(image_path)  # Remove .convert('L') to keep the image in color\n",
        "                # Resize image to the target size\n",
        "                resized_image = image.resize(target_size)\n",
        "                # Crop image\n",
        "                width, height = resized_image.size\n",
        "                left = (width - crop_size[0]) // 2\n",
        "                top = (height - crop_size[1]) // 2\n",
        "                right = left + crop_size[0]\n",
        "                bottom = top + crop_size[1]\n",
        "                cropped_image = resized_image.crop((left, top, right, bottom))\n",
        "\n",
        "                cropped_images.append(cropped_image)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image: {image_path}, Error: {e}\")\n",
        "\n",
        "    return cropped_images\n",
        "\n",
        "# Load and preprocess the dataset with adjusted target_size\n",
        "folder_path = \"/content/drive/MyDrive/Project3/SegmentedImages\"\n",
        "cropped_images = resize_and_crop_dataset(folder_path, target_size=(64, 64))\n",
        "\n",
        "# Check if cropped_images list is not empty\n",
        "if cropped_images:\n",
        "    # Print three random images\n",
        "    random_images = random.sample(cropped_images, min(3, len(cropped_images)))\n",
        "\n",
        "    for i, image in enumerate(random_images, start=1):\n",
        "        print(f\"Random Image {i}:\")\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')  # Turn off axis labels\n",
        "        plt.show() # Display the image\n",
        "else:\n",
        "    print(\"No images found or images couldn't be loaded properly.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO5OR8etWFdY"
      },
      "source": [
        "## GAN Model Building\n",
        "Generative Adversial Network(GAN) contains two neural networks.Those are **Generator** and **Discriminator**.\n",
        "Generator generates the images based on the trained dataset and discriminator detects whether the generated image is real or fake.\n",
        "\n",
        "\n",
        "**Generator**:\n",
        "In the below generator function contains\n",
        "*   Encoder :- 2 Conv2D layers(contains Batch Normalization and Leaky Relu Layers).\n",
        "*   Residual Blocks :-12 Conv2D layers with 2 in a for loop as similar to the encoder.\n",
        "*   Decoder :- 2Conv2D layers\n",
        "\n",
        "\n",
        "**Discriminator**:\n",
        "It contains\n",
        "\n",
        "*   3 Conv2D layers\n",
        "*   1 Flatten Layer\n",
        "*   1 Dense Layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Optimizer**\n",
        "\n",
        "Adam is a popular optimizer for training neural networks because it combines the benefits of two other widely-used optimization algorithms: AdaGrad and RMSProp. Here are some reasons why Adam is commonly used:\n",
        "\n",
        "Adaptive Learning Rate: Adam adapts the learning rate for each parameter individually, which helps in faster convergence and better performance. It computes adaptive learning rates for each parameter based on the first and second moments of the gradients.\n",
        "\n",
        "Efficient: Adam efficiently updates the learning rates during training, allowing for faster convergence compared to traditional gradient descent algorithms.\n",
        "\n",
        "Easy to Use: Adam does not require manual tuning of the learning rate, making it easier to use for a wide range of problems. It typically works well with default hyperparameters.\n",
        "\n",
        "Robustness: Adam is known to work well across a wide range of deep learning architectures and problem domains. It is robust to noisy gradients and sparse data.\n",
        "\n",
        "Regularization Effect: Adam has a built-in L2 regularization effect, which helps prevent overfitting to some extent.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x9TNh9cpSJL",
        "outputId": "0f98e467-3f15-4f2b-93c0-a0f51e6d8d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator Summary:\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 64)        256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation (Activation)     (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 16, 16, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 16, 16, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 16, 16, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2  (None, 32, 32, 128)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 32, 32, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 32, 32, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSamplin  (None, 64, 64, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 64, 64, 1)         577       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1927041 (7.35 MB)\n",
            "Trainable params: 1923457 (7.34 MB)\n",
            "Non-trainable params: 3584 (14.00 KB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Discriminator Summary:\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 64)        640       \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 16, 16, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 8, 8, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 16385     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 387585 (1.48 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 387585 (1.48 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "GAN Summary:\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 64, 64, 1)]       0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 64, 64, 1)         1927041   \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 1)                 387585    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2314626 (8.83 MB)\n",
            "Trainable params: 1923457 (7.34 MB)\n",
            "Non-trainable params: 391169 (1.49 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# Define the generator model\n",
        "def build_generator(input_shape):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Encoder\n",
        "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(6):\n",
        "        model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Activation('relu'))\n",
        "        model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "\n",
        "    # Decoder\n",
        "    model.add(layers.UpSampling2D())\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "\n",
        "    model.add(layers.UpSampling2D())\n",
        "    model.add(layers.Conv2D(1, (3, 3), padding='same', activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the discriminator model\n",
        "def build_discriminator(input_shape):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the input shape for the generator\n",
        "input_shape = (64, 64, 1)  # Adjust based on your input image size and channels\n",
        "\n",
        "# Build the generator and discriminator models\n",
        "generator = build_generator(input_shape)\n",
        "discriminator = build_discriminator(input_shape)\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator.compile(optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Freeze the discriminator's weights during GAN training\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build the GAN model\n",
        "gan_input = layers.Input(shape=input_shape)\n",
        "generated_image = generator(gan_input)\n",
        "gan_output = discriminator(generated_image)\n",
        "gan = models.Model(gan_input, gan_output)\n",
        "\n",
        "# Compile the GAN model\n",
        "gan.compile(optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "            loss='binary_crossentropy')\n",
        "\n",
        "# Print summary of the models\n",
        "print(\"Generator Summary:\")\n",
        "generator.summary()\n",
        "\n",
        "print(\"\\nDiscriminator Summary:\")\n",
        "discriminator.summary()\n",
        "\n",
        "print(\"\\nGAN Summary:\")\n",
        "gan.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOumz8k6f26K"
      },
      "source": [
        "## Model Training\n",
        "After building the GAN model , it is called and then trained on the segmented images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trJKS69Epyxi",
        "outputId": "a86c0082-4d44-4d22-ac83-3196ce265f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 3s 1s/step\n",
            "Epoch 1/500, Discriminator Loss: 0.9328232407569885, Generator Loss: 0.7068131566047668\n",
            "2/2 [==============================] - 2s 804ms/step\n",
            "Epoch 2/500, Discriminator Loss: 0.44024303555488586, Generator Loss: 0.6793861389160156\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 3/500, Discriminator Loss: 0.485626757144928, Generator Loss: 0.674530029296875\n",
            "2/2 [==============================] - 1s 658ms/step\n",
            "Epoch 4/500, Discriminator Loss: 0.4626817852258682, Generator Loss: 0.6986769437789917\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 5/500, Discriminator Loss: 0.1362388078123331, Generator Loss: 0.7389070987701416\n",
            "2/2 [==============================] - 1s 700ms/step\n",
            "Epoch 6/500, Discriminator Loss: 0.08252217248082161, Generator Loss: 0.7190690040588379\n",
            "2/2 [==============================] - 2s 948ms/step\n",
            "Epoch 7/500, Discriminator Loss: 0.10718843713402748, Generator Loss: 0.7343190908432007\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 8/500, Discriminator Loss: 0.04046649485826492, Generator Loss: 0.7582684755325317\n",
            "2/2 [==============================] - 1s 641ms/step\n",
            "Epoch 9/500, Discriminator Loss: 0.0681625884026289, Generator Loss: 0.7433162927627563\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 10/500, Discriminator Loss: 0.15663999132812023, Generator Loss: 0.6613694429397583\n",
            "2/2 [==============================] - 1s 657ms/step\n",
            "Epoch 11/500, Discriminator Loss: 0.03686012513935566, Generator Loss: 0.5930118560791016\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 12/500, Discriminator Loss: 0.0173369818367064, Generator Loss: 0.5588915944099426\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 13/500, Discriminator Loss: 0.018337602727115154, Generator Loss: 0.5326789617538452\n",
            "2/2 [==============================] - 1s 643ms/step\n",
            "Epoch 14/500, Discriminator Loss: 0.017273247241973877, Generator Loss: 0.5105435252189636\n",
            "2/2 [==============================] - 2s 639ms/step\n",
            "Epoch 15/500, Discriminator Loss: 0.013142942450940609, Generator Loss: 0.4974590539932251\n",
            "2/2 [==============================] - 1s 621ms/step\n",
            "Epoch 16/500, Discriminator Loss: 0.009983947733417153, Generator Loss: 0.48334020376205444\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 17/500, Discriminator Loss: 0.007443261332809925, Generator Loss: 0.4696895182132721\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 18/500, Discriminator Loss: 0.005969625897705555, Generator Loss: 0.4561134874820709\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 19/500, Discriminator Loss: 0.006685940781608224, Generator Loss: 0.4457785189151764\n",
            "2/2 [==============================] - 1s 634ms/step\n",
            "Epoch 20/500, Discriminator Loss: 0.007179060718044639, Generator Loss: 0.43424755334854126\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 21/500, Discriminator Loss: 0.009251176379621029, Generator Loss: 0.42236751317977905\n",
            "2/2 [==============================] - 2s 873ms/step\n",
            "Epoch 22/500, Discriminator Loss: 0.007511652773246169, Generator Loss: 0.412142813205719\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 23/500, Discriminator Loss: 0.00712257856503129, Generator Loss: 0.4002675414085388\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 24/500, Discriminator Loss: 0.007658978458493948, Generator Loss: 0.3909493386745453\n",
            "2/2 [==============================] - 1s 643ms/step\n",
            "Epoch 25/500, Discriminator Loss: 0.008983662817627192, Generator Loss: 0.38279464840888977\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 26/500, Discriminator Loss: 0.006591207347810268, Generator Loss: 0.37149062752723694\n",
            "2/2 [==============================] - 1s 762ms/step\n",
            "Epoch 27/500, Discriminator Loss: 0.009374606423079967, Generator Loss: 0.36229604482650757\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 28/500, Discriminator Loss: 0.009341048076748848, Generator Loss: 0.35578712821006775\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 29/500, Discriminator Loss: 0.011559655889868736, Generator Loss: 0.354206919670105\n",
            "2/2 [==============================] - 1s 660ms/step\n",
            "Epoch 30/500, Discriminator Loss: 0.007381365983746946, Generator Loss: 0.35072606801986694\n",
            "2/2 [==============================] - 1s 624ms/step\n",
            "Epoch 31/500, Discriminator Loss: 0.009609634056687355, Generator Loss: 0.3456975221633911\n",
            "2/2 [==============================] - 1s 643ms/step\n",
            "Epoch 32/500, Discriminator Loss: 0.005880551994778216, Generator Loss: 0.3438063859939575\n",
            "2/2 [==============================] - 1s 625ms/step\n",
            "Epoch 33/500, Discriminator Loss: 0.01723833242431283, Generator Loss: 0.3689737617969513\n",
            "2/2 [==============================] - 1s 635ms/step\n",
            "Epoch 34/500, Discriminator Loss: 0.005143769027199596, Generator Loss: 0.3561316728591919\n",
            "2/2 [==============================] - 1s 779ms/step\n",
            "Epoch 35/500, Discriminator Loss: 0.007554610027000308, Generator Loss: 0.3488006293773651\n",
            "2/2 [==============================] - 1s 637ms/step\n",
            "Epoch 36/500, Discriminator Loss: 0.006322233472019434, Generator Loss: 0.3447778820991516\n",
            "2/2 [==============================] - 1s 660ms/step\n",
            "Epoch 37/500, Discriminator Loss: 0.012759434059262276, Generator Loss: 0.3687337636947632\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 38/500, Discriminator Loss: 0.004334592442319263, Generator Loss: 0.37051957845687866\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 39/500, Discriminator Loss: 0.0076151874382048845, Generator Loss: 0.37163645029067993\n",
            "2/2 [==============================] - 1s 658ms/step\n",
            "Epoch 40/500, Discriminator Loss: 0.003384048119187355, Generator Loss: 0.36019057035446167\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 41/500, Discriminator Loss: 0.00550918304361403, Generator Loss: 0.3590925335884094\n",
            "2/2 [==============================] - 1s 665ms/step\n",
            "Epoch 42/500, Discriminator Loss: 0.0068395910784602165, Generator Loss: 0.3750288486480713\n",
            "2/2 [==============================] - 2s 650ms/step\n",
            "Epoch 43/500, Discriminator Loss: 0.00323011155705899, Generator Loss: 0.3604295253753662\n",
            "2/2 [==============================] - 1s 625ms/step\n",
            "Epoch 44/500, Discriminator Loss: 0.003095561172813177, Generator Loss: 0.3422536849975586\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 45/500, Discriminator Loss: 0.004080217971932143, Generator Loss: 0.3330644965171814\n",
            "2/2 [==============================] - 2s 644ms/step\n",
            "Epoch 46/500, Discriminator Loss: 0.007186097791418433, Generator Loss: 0.33120399713516235\n",
            "2/2 [==============================] - 1s 627ms/step\n",
            "Epoch 47/500, Discriminator Loss: 0.006352412048727274, Generator Loss: 0.3337574601173401\n",
            "2/2 [==============================] - 1s 629ms/step\n",
            "Epoch 48/500, Discriminator Loss: 0.0018036156543530524, Generator Loss: 0.3285468518733978\n",
            "2/2 [==============================] - 1s 642ms/step\n",
            "Epoch 49/500, Discriminator Loss: 0.024679458350874484, Generator Loss: 0.41949474811553955\n",
            "2/2 [==============================] - 1s 714ms/step\n",
            "Epoch 50/500, Discriminator Loss: 0.00507173166533903, Generator Loss: 0.44495826959609985\n",
            "2/2 [==============================] - 1s 661ms/step\n",
            "Epoch 51/500, Discriminator Loss: 0.006086607612814987, Generator Loss: 0.4040224254131317\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 52/500, Discriminator Loss: 0.0026128184981644154, Generator Loss: 0.370486319065094\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 53/500, Discriminator Loss: 0.004307030234485865, Generator Loss: 0.36087045073509216\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 54/500, Discriminator Loss: 0.008538799826055765, Generator Loss: 0.33112668991088867\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 55/500, Discriminator Loss: 0.00951499619986862, Generator Loss: 0.3359695076942444\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 56/500, Discriminator Loss: 0.0024022910511121154, Generator Loss: 0.3098593056201935\n",
            "2/2 [==============================] - 1s 643ms/step\n",
            "Epoch 57/500, Discriminator Loss: 0.00475463189650327, Generator Loss: 0.27921250462532043\n",
            "2/2 [==============================] - 2s 629ms/step\n",
            "Epoch 58/500, Discriminator Loss: 0.040555122308433056, Generator Loss: 0.40943658351898193\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 59/500, Discriminator Loss: 0.003075968393659423, Generator Loss: 0.4858131408691406\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 60/500, Discriminator Loss: 0.0037109398308530217, Generator Loss: 0.4573627710342407\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 61/500, Discriminator Loss: 0.06529443734325469, Generator Loss: 0.6544041633605957\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 62/500, Discriminator Loss: 0.006593542391783558, Generator Loss: 0.5984166860580444\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 63/500, Discriminator Loss: 0.013999086950207129, Generator Loss: 0.42122703790664673\n",
            "2/2 [==============================] - 1s 775ms/step\n",
            "Epoch 64/500, Discriminator Loss: 0.008566667907871306, Generator Loss: 0.30060628056526184\n",
            "2/2 [==============================] - 1s 636ms/step\n",
            "Epoch 65/500, Discriminator Loss: 0.007507630158215761, Generator Loss: 0.24391141533851624\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 66/500, Discriminator Loss: 0.00518450397066772, Generator Loss: 0.2015133649110794\n",
            "2/2 [==============================] - 1s 678ms/step\n",
            "Epoch 67/500, Discriminator Loss: 0.004333274671807885, Generator Loss: 0.18088459968566895\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 68/500, Discriminator Loss: 0.0066070351749658585, Generator Loss: 0.17130489647388458\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 69/500, Discriminator Loss: 0.008126808796077967, Generator Loss: 0.16459819674491882\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 70/500, Discriminator Loss: 0.004132595029659569, Generator Loss: 0.15629538893699646\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 71/500, Discriminator Loss: 0.0029925917042419314, Generator Loss: 0.1429131031036377\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 72/500, Discriminator Loss: 0.007792716613039374, Generator Loss: 0.1487785428762436\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 73/500, Discriminator Loss: 0.004856694955378771, Generator Loss: 0.1569773256778717\n",
            "2/2 [==============================] - 1s 661ms/step\n",
            "Epoch 74/500, Discriminator Loss: 0.01122511737048626, Generator Loss: 0.1988416314125061\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 75/500, Discriminator Loss: 0.0038988625165075064, Generator Loss: 0.22193971276283264\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 76/500, Discriminator Loss: 0.008924271911382675, Generator Loss: 0.21867471933364868\n",
            "2/2 [==============================] - 1s 638ms/step\n",
            "Epoch 77/500, Discriminator Loss: 0.009475465165451169, Generator Loss: 0.25843697786331177\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 78/500, Discriminator Loss: 0.004440425545908511, Generator Loss: 0.27449658513069153\n",
            "2/2 [==============================] - 1s 643ms/step\n",
            "Epoch 79/500, Discriminator Loss: 0.004488016711547971, Generator Loss: 0.2280854433774948\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 80/500, Discriminator Loss: 0.03671621344983578, Generator Loss: 0.39268431067466736\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 81/500, Discriminator Loss: 0.007827161171007901, Generator Loss: 0.5073719024658203\n",
            "2/2 [==============================] - 1s 657ms/step\n",
            "Epoch 82/500, Discriminator Loss: 0.004510515587753616, Generator Loss: 0.46299928426742554\n",
            "2/2 [==============================] - 1s 655ms/step\n",
            "Epoch 83/500, Discriminator Loss: 0.011209847871214151, Generator Loss: 0.40404820442199707\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 84/500, Discriminator Loss: 0.012467836495488882, Generator Loss: 0.3307511806488037\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 85/500, Discriminator Loss: 0.005631095758872107, Generator Loss: 0.2818828225135803\n",
            "2/2 [==============================] - 2s 814ms/step\n",
            "Epoch 86/500, Discriminator Loss: 0.008435702417045832, Generator Loss: 0.23602262139320374\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 87/500, Discriminator Loss: 0.003926954930648208, Generator Loss: 0.18862178921699524\n",
            "2/2 [==============================] - 1s 641ms/step\n",
            "Epoch 88/500, Discriminator Loss: 0.0033736362820491195, Generator Loss: 0.14659294486045837\n",
            "2/2 [==============================] - 1s 635ms/step\n",
            "Epoch 89/500, Discriminator Loss: 0.006784494966268539, Generator Loss: 0.13046331703662872\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 90/500, Discriminator Loss: 0.0037237817887216806, Generator Loss: 0.12367065995931625\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 91/500, Discriminator Loss: 0.0025362587766721845, Generator Loss: 0.11204993724822998\n",
            "2/2 [==============================] - 1s 627ms/step\n",
            "Epoch 92/500, Discriminator Loss: 0.0031500502955168486, Generator Loss: 0.10246677696704865\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 93/500, Discriminator Loss: 0.003388880635611713, Generator Loss: 0.0967666506767273\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 94/500, Discriminator Loss: 0.0028130178106948733, Generator Loss: 0.08984730392694473\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 95/500, Discriminator Loss: 0.0023585043381899595, Generator Loss: 0.08034743368625641\n",
            "2/2 [==============================] - 1s 634ms/step\n",
            "Epoch 96/500, Discriminator Loss: 0.0025072533171623945, Generator Loss: 0.07245280593633652\n",
            "2/2 [==============================] - 1s 630ms/step\n",
            "Epoch 97/500, Discriminator Loss: 0.0023448819993063807, Generator Loss: 0.06558700650930405\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 98/500, Discriminator Loss: 0.0020358795300126076, Generator Loss: 0.05960603058338165\n",
            "2/2 [==============================] - 1s 633ms/step\n",
            "Epoch 99/500, Discriminator Loss: 0.002276297309435904, Generator Loss: 0.05438940227031708\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 100/500, Discriminator Loss: 0.0019188520382158458, Generator Loss: 0.04994875192642212\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 101/500, Discriminator Loss: 0.0016900249756872654, Generator Loss: 0.045875925570726395\n",
            "2/2 [==============================] - 1s 661ms/step\n",
            "Epoch 102/500, Discriminator Loss: 0.0018558374140411615, Generator Loss: 0.041917651891708374\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 103/500, Discriminator Loss: 0.0014317811001092196, Generator Loss: 0.03848773241043091\n",
            "2/2 [==============================] - 1s 662ms/step\n",
            "Epoch 104/500, Discriminator Loss: 0.0017029930022545159, Generator Loss: 0.03544393926858902\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 105/500, Discriminator Loss: 0.001357324596028775, Generator Loss: 0.03341023251414299\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 106/500, Discriminator Loss: 0.0014931116020306945, Generator Loss: 0.03150918334722519\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 107/500, Discriminator Loss: 0.0014260102761909366, Generator Loss: 0.029700033366680145\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 108/500, Discriminator Loss: 0.0013549582217819989, Generator Loss: 0.027872653678059578\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 109/500, Discriminator Loss: 0.001538457814604044, Generator Loss: 0.026499327272176743\n",
            "2/2 [==============================] - 1s 632ms/step\n",
            "Epoch 110/500, Discriminator Loss: 0.0015219039050862193, Generator Loss: 0.025098685175180435\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 111/500, Discriminator Loss: 0.0014856321504339576, Generator Loss: 0.023750795051455498\n",
            "2/2 [==============================] - 2s 895ms/step\n",
            "Epoch 112/500, Discriminator Loss: 0.0015978403389453888, Generator Loss: 0.02220875397324562\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 113/500, Discriminator Loss: 0.00160864123608917, Generator Loss: 0.020812517032027245\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 114/500, Discriminator Loss: 0.0013594460906460881, Generator Loss: 0.01972050964832306\n",
            "2/2 [==============================] - 1s 695ms/step\n",
            "Epoch 115/500, Discriminator Loss: 0.0016450094990432262, Generator Loss: 0.01872921735048294\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 116/500, Discriminator Loss: 0.0016635089414194226, Generator Loss: 0.018048306927084923\n",
            "2/2 [==============================] - 1s 665ms/step\n",
            "Epoch 117/500, Discriminator Loss: 0.0018375626532360911, Generator Loss: 0.017201371490955353\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 118/500, Discriminator Loss: 0.0012148451060056686, Generator Loss: 0.016427844762802124\n",
            "2/2 [==============================] - 1s 668ms/step\n",
            "Epoch 119/500, Discriminator Loss: 0.0010718577832449228, Generator Loss: 0.01562293991446495\n",
            "2/2 [==============================] - 1s 666ms/step\n",
            "Epoch 120/500, Discriminator Loss: 0.0011477062362246215, Generator Loss: 0.014593173749744892\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 121/500, Discriminator Loss: 0.0014212120440788567, Generator Loss: 0.013753196224570274\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 122/500, Discriminator Loss: 0.0012334572966210544, Generator Loss: 0.013025365769863129\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 123/500, Discriminator Loss: 0.00109175406396389, Generator Loss: 0.012437291443347931\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 124/500, Discriminator Loss: 0.0012283638352528214, Generator Loss: 0.011666974052786827\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 125/500, Discriminator Loss: 0.0011422435636632144, Generator Loss: 0.011032159440219402\n",
            "2/2 [==============================] - 1s 642ms/step\n",
            "Epoch 126/500, Discriminator Loss: 0.0010996244964189827, Generator Loss: 0.010384265333414078\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 127/500, Discriminator Loss: 0.0009007158514577895, Generator Loss: 0.009828232228755951\n",
            "2/2 [==============================] - 1s 680ms/step\n",
            "Epoch 128/500, Discriminator Loss: 0.0011930741602554917, Generator Loss: 0.009270627051591873\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 129/500, Discriminator Loss: 0.0008673664415255189, Generator Loss: 0.008799463510513306\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 130/500, Discriminator Loss: 0.0010050892597064376, Generator Loss: 0.008421317674219608\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 131/500, Discriminator Loss: 0.0009311623580288142, Generator Loss: 0.007981406524777412\n",
            "2/2 [==============================] - 1s 673ms/step\n",
            "Epoch 132/500, Discriminator Loss: 0.0011773657170124352, Generator Loss: 0.0075879767537117004\n",
            "2/2 [==============================] - 1s 629ms/step\n",
            "Epoch 133/500, Discriminator Loss: 0.0009099407179746777, Generator Loss: 0.0071943760849535465\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 134/500, Discriminator Loss: 0.0008772848232183605, Generator Loss: 0.006837449036538601\n",
            "2/2 [==============================] - 2s 645ms/step\n",
            "Epoch 135/500, Discriminator Loss: 0.0009118517336901277, Generator Loss: 0.0064690373837947845\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 136/500, Discriminator Loss: 0.0009578753670211881, Generator Loss: 0.006100315134972334\n",
            "2/2 [==============================] - 1s 671ms/step\n",
            "Epoch 137/500, Discriminator Loss: 0.0007725927862338722, Generator Loss: 0.005833321716636419\n",
            "2/2 [==============================] - 2s 667ms/step\n",
            "Epoch 138/500, Discriminator Loss: 0.0007248060719575733, Generator Loss: 0.005556262098252773\n",
            "2/2 [==============================] - 1s 635ms/step\n",
            "Epoch 139/500, Discriminator Loss: 0.000720447365893051, Generator Loss: 0.005261931102722883\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 140/500, Discriminator Loss: 0.0007781897438690066, Generator Loss: 0.0050160763785243034\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 141/500, Discriminator Loss: 0.000722594908438623, Generator Loss: 0.004753983113914728\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 142/500, Discriminator Loss: 0.0006462885939981788, Generator Loss: 0.00459199957549572\n",
            "2/2 [==============================] - 1s 673ms/step\n",
            "Epoch 143/500, Discriminator Loss: 0.0007145202253013849, Generator Loss: 0.004311561118811369\n",
            "2/2 [==============================] - 1s 753ms/step\n",
            "Epoch 144/500, Discriminator Loss: 0.000797580840298906, Generator Loss: 0.004128233063966036\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 145/500, Discriminator Loss: 0.0007316729752346873, Generator Loss: 0.003943603951483965\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 146/500, Discriminator Loss: 0.00072539719985798, Generator Loss: 0.003731265664100647\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 147/500, Discriminator Loss: 0.000723974546417594, Generator Loss: 0.0035462011583149433\n",
            "2/2 [==============================] - 1s 636ms/step\n",
            "Epoch 148/500, Discriminator Loss: 0.0007213548524305224, Generator Loss: 0.0033807759173214436\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 149/500, Discriminator Loss: 0.0006828256591688842, Generator Loss: 0.003220378654077649\n",
            "2/2 [==============================] - 1s 635ms/step\n",
            "Epoch 150/500, Discriminator Loss: 0.0005567064363276586, Generator Loss: 0.0030984384939074516\n",
            "2/2 [==============================] - 1s 663ms/step\n",
            "Epoch 151/500, Discriminator Loss: 0.0006253342144191265, Generator Loss: 0.002958479803055525\n",
            "2/2 [==============================] - 2s 849ms/step\n",
            "Epoch 152/500, Discriminator Loss: 0.0007545680564362556, Generator Loss: 0.0027993691619485617\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 153/500, Discriminator Loss: 0.000613012321991846, Generator Loss: 0.002718646079301834\n",
            "2/2 [==============================] - 1s 633ms/step\n",
            "Epoch 154/500, Discriminator Loss: 0.0006809342885389924, Generator Loss: 0.002590570133179426\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 155/500, Discriminator Loss: 0.0007590886962134391, Generator Loss: 0.002492615720257163\n",
            "2/2 [==============================] - 1s 668ms/step\n",
            "Epoch 156/500, Discriminator Loss: 0.000672851805575192, Generator Loss: 0.0023837373591959476\n",
            "2/2 [==============================] - 1s 666ms/step\n",
            "Epoch 157/500, Discriminator Loss: 0.0005903732962906361, Generator Loss: 0.002301929984241724\n",
            "2/2 [==============================] - 1s 627ms/step\n",
            "Epoch 158/500, Discriminator Loss: 0.0006396097596734762, Generator Loss: 0.002194203669205308\n",
            "2/2 [==============================] - 1s 669ms/step\n",
            "Epoch 159/500, Discriminator Loss: 0.0006709132285322994, Generator Loss: 0.002106910338625312\n",
            "2/2 [==============================] - 1s 632ms/step\n",
            "Epoch 160/500, Discriminator Loss: 0.0005673407576978207, Generator Loss: 0.0020222056191414595\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 161/500, Discriminator Loss: 0.0006646594847552478, Generator Loss: 0.0019438073504716158\n",
            "2/2 [==============================] - 1s 642ms/step\n",
            "Epoch 162/500, Discriminator Loss: 0.0006155192677397281, Generator Loss: 0.0018808292225003242\n",
            "2/2 [==============================] - 2s 831ms/step\n",
            "Epoch 163/500, Discriminator Loss: 0.0006282647082116455, Generator Loss: 0.0018009105697274208\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 164/500, Discriminator Loss: 0.0005591361550614238, Generator Loss: 0.001760219456627965\n",
            "2/2 [==============================] - 1s 654ms/step\n",
            "Epoch 165/500, Discriminator Loss: 0.0005512843490578234, Generator Loss: 0.0017026872374117374\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 166/500, Discriminator Loss: 0.0005819128127768636, Generator Loss: 0.0016364969778805971\n",
            "2/2 [==============================] - 1s 635ms/step\n",
            "Epoch 167/500, Discriminator Loss: 0.0006111318944022059, Generator Loss: 0.001592452870681882\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 168/500, Discriminator Loss: 0.0004885387606918812, Generator Loss: 0.001555048511363566\n",
            "2/2 [==============================] - 1s 638ms/step\n",
            "Epoch 169/500, Discriminator Loss: 0.0005628596700262278, Generator Loss: 0.0015055573312565684\n",
            "2/2 [==============================] - 1s 661ms/step\n",
            "Epoch 170/500, Discriminator Loss: 0.00046781639684922993, Generator Loss: 0.001462823711335659\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 171/500, Discriminator Loss: 0.0005655593995470554, Generator Loss: 0.0014139637351036072\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 172/500, Discriminator Loss: 0.0007141177193261683, Generator Loss: 0.0013724388554692268\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 173/500, Discriminator Loss: 0.0005999738641548902, Generator Loss: 0.0013339412398636341\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 174/500, Discriminator Loss: 0.0006121680198702961, Generator Loss: 0.001304129371419549\n",
            "2/2 [==============================] - 1s 654ms/step\n",
            "Epoch 175/500, Discriminator Loss: 0.0004960750520695001, Generator Loss: 0.0012884533498436213\n",
            "2/2 [==============================] - 1s 637ms/step\n",
            "Epoch 176/500, Discriminator Loss: 0.0005285273218760267, Generator Loss: 0.001257050782442093\n",
            "2/2 [==============================] - 2s 895ms/step\n",
            "Epoch 177/500, Discriminator Loss: 0.00045796453196089715, Generator Loss: 0.001240343670360744\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 178/500, Discriminator Loss: 0.0005356323817977682, Generator Loss: 0.0012124271597713232\n",
            "2/2 [==============================] - 1s 670ms/step\n",
            "Epoch 179/500, Discriminator Loss: 0.00053631910122931, Generator Loss: 0.0011931756744161248\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 180/500, Discriminator Loss: 0.0004833172570215538, Generator Loss: 0.001151096890680492\n",
            "2/2 [==============================] - 1s 672ms/step\n",
            "Epoch 181/500, Discriminator Loss: 0.0005447319126687944, Generator Loss: 0.0011321494821459055\n",
            "2/2 [==============================] - 2s 729ms/step\n",
            "Epoch 182/500, Discriminator Loss: 0.0005399525398388505, Generator Loss: 0.0011098082177340984\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 183/500, Discriminator Loss: 0.0005504583241418004, Generator Loss: 0.001071686390787363\n",
            "2/2 [==============================] - 1s 667ms/step\n",
            "Epoch 184/500, Discriminator Loss: 0.0004423993086675182, Generator Loss: 0.0010575575288385153\n",
            "2/2 [==============================] - 2s 907ms/step\n",
            "Epoch 185/500, Discriminator Loss: 0.0006795252847950906, Generator Loss: 0.0010465802624821663\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 186/500, Discriminator Loss: 0.0004964428953826427, Generator Loss: 0.001046929508447647\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 187/500, Discriminator Loss: 0.0004887953109573573, Generator Loss: 0.0010171234607696533\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 188/500, Discriminator Loss: 0.000509305318701081, Generator Loss: 0.001003750367090106\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 189/500, Discriminator Loss: 0.0004943571984767914, Generator Loss: 0.000995232374407351\n",
            "2/2 [==============================] - 1s 635ms/step\n",
            "Epoch 190/500, Discriminator Loss: 0.0004640322586055845, Generator Loss: 0.0010058516636490822\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 191/500, Discriminator Loss: 0.0005287834501359612, Generator Loss: 0.0009830226190388203\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 192/500, Discriminator Loss: 0.000494318432174623, Generator Loss: 0.0009585586376488209\n",
            "2/2 [==============================] - 2s 640ms/step\n",
            "Epoch 193/500, Discriminator Loss: 0.0005621948512271047, Generator Loss: 0.0009545300854369998\n",
            "2/2 [==============================] - 1s 675ms/step\n",
            "Epoch 194/500, Discriminator Loss: 0.0005330726853571832, Generator Loss: 0.0009371822234243155\n",
            "2/2 [==============================] - 1s 637ms/step\n",
            "Epoch 195/500, Discriminator Loss: 0.0004335547419032082, Generator Loss: 0.0009404446464031935\n",
            "2/2 [==============================] - 1s 668ms/step\n",
            "Epoch 196/500, Discriminator Loss: 0.00043889787048101425, Generator Loss: 0.0009364034049212933\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 197/500, Discriminator Loss: 0.0004931924195261672, Generator Loss: 0.0009270325535908341\n",
            "2/2 [==============================] - 1s 668ms/step\n",
            "Epoch 198/500, Discriminator Loss: 0.0005299447220750153, Generator Loss: 0.0009112046100199223\n",
            "2/2 [==============================] - 1s 643ms/step\n",
            "Epoch 199/500, Discriminator Loss: 0.00047150428872555494, Generator Loss: 0.0009049257496371865\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 200/500, Discriminator Loss: 0.00042671240225899965, Generator Loss: 0.0009088902734220028\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 201/500, Discriminator Loss: 0.0005622304161079228, Generator Loss: 0.0008966347086243331\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 202/500, Discriminator Loss: 0.0005370019352994859, Generator Loss: 0.0008819923386909068\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 203/500, Discriminator Loss: 0.0004847242234973237, Generator Loss: 0.0008826243574731052\n",
            "2/2 [==============================] - 1s 667ms/step\n",
            "Epoch 204/500, Discriminator Loss: 0.00041787081863731146, Generator Loss: 0.0008811397710815072\n",
            "2/2 [==============================] - 1s 665ms/step\n",
            "Epoch 205/500, Discriminator Loss: 0.0004942405212204903, Generator Loss: 0.0008713740389794111\n",
            "2/2 [==============================] - 1s 729ms/step\n",
            "Epoch 206/500, Discriminator Loss: 0.0005804557586088777, Generator Loss: 0.0008608761709183455\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 207/500, Discriminator Loss: 0.00046326305891852826, Generator Loss: 0.0008476912626065314\n",
            "2/2 [==============================] - 1s 638ms/step\n",
            "Epoch 208/500, Discriminator Loss: 0.00048548584163654596, Generator Loss: 0.000839660526253283\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 209/500, Discriminator Loss: 0.0005049386236350983, Generator Loss: 0.0008391226874664426\n",
            "2/2 [==============================] - 1s 670ms/step\n",
            "Epoch 210/500, Discriminator Loss: 0.0004741004086099565, Generator Loss: 0.0008274732972495258\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 211/500, Discriminator Loss: 0.000506536744069308, Generator Loss: 0.0008236754219979048\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 212/500, Discriminator Loss: 0.00045562093146145344, Generator Loss: 0.000828580348752439\n",
            "2/2 [==============================] - 1s 654ms/step\n",
            "Epoch 213/500, Discriminator Loss: 0.0004933690361212939, Generator Loss: 0.0008140818681567907\n",
            "2/2 [==============================] - 1s 637ms/step\n",
            "Epoch 214/500, Discriminator Loss: 0.00040605320828035474, Generator Loss: 0.0007931759464554489\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 215/500, Discriminator Loss: 0.000437864480772987, Generator Loss: 0.0007837310549803078\n",
            "2/2 [==============================] - 1s 664ms/step\n",
            "Epoch 216/500, Discriminator Loss: 0.0004092640883754939, Generator Loss: 0.0007696428801864386\n",
            "2/2 [==============================] - 2s 657ms/step\n",
            "Epoch 217/500, Discriminator Loss: 0.0005208801594562829, Generator Loss: 0.000766131968703121\n",
            "2/2 [==============================] - 1s 664ms/step\n",
            "Epoch 218/500, Discriminator Loss: 0.0005272493581287563, Generator Loss: 0.0007412806153297424\n",
            "2/2 [==============================] - 1s 662ms/step\n",
            "Epoch 219/500, Discriminator Loss: 0.0005110510246595368, Generator Loss: 0.000732800574041903\n",
            "2/2 [==============================] - 2s 682ms/step\n",
            "Epoch 220/500, Discriminator Loss: 0.0004674872907344252, Generator Loss: 0.000722058757673949\n",
            "2/2 [==============================] - 1s 665ms/step\n",
            "Epoch 221/500, Discriminator Loss: 0.0005018867959734052, Generator Loss: 0.0007098288624547422\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 222/500, Discriminator Loss: 0.0004099806828889996, Generator Loss: 0.0007104568649083376\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 223/500, Discriminator Loss: 0.0004955738695571199, Generator Loss: 0.0006923972396180034\n",
            "2/2 [==============================] - 1s 721ms/step\n",
            "Epoch 224/500, Discriminator Loss: 0.0005552755028475076, Generator Loss: 0.0006896378472447395\n",
            "2/2 [==============================] - 1s 672ms/step\n",
            "Epoch 225/500, Discriminator Loss: 0.0005963837029412389, Generator Loss: 0.0006852603401057422\n",
            "2/2 [==============================] - 1s 639ms/step\n",
            "Epoch 226/500, Discriminator Loss: 0.00048677041195333004, Generator Loss: 0.0006894582766108215\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 227/500, Discriminator Loss: 0.0004977829230483621, Generator Loss: 0.0006943563930690289\n",
            "2/2 [==============================] - 1s 633ms/step\n",
            "Epoch 228/500, Discriminator Loss: 0.00047543163236696273, Generator Loss: 0.0006963478517718613\n",
            "2/2 [==============================] - 1s 633ms/step\n",
            "Epoch 229/500, Discriminator Loss: 0.0004413645074237138, Generator Loss: 0.000707622617483139\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 230/500, Discriminator Loss: 0.0005087873141746968, Generator Loss: 0.0007023568032309413\n",
            "2/2 [==============================] - 1s 655ms/step\n",
            "Epoch 231/500, Discriminator Loss: 0.0004491421132115647, Generator Loss: 0.0006991873378865421\n",
            "2/2 [==============================] - 1s 661ms/step\n",
            "Epoch 232/500, Discriminator Loss: 0.00047966596321202815, Generator Loss: 0.0006993181305006146\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 233/500, Discriminator Loss: 0.000456391426268965, Generator Loss: 0.0006701375241391361\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 234/500, Discriminator Loss: 0.0005368467245716602, Generator Loss: 0.000661113765090704\n",
            "2/2 [==============================] - 1s 671ms/step\n",
            "Epoch 235/500, Discriminator Loss: 0.0005095225351396948, Generator Loss: 0.0006537805311381817\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 236/500, Discriminator Loss: 0.0004988477594451979, Generator Loss: 0.000676930823829025\n",
            "2/2 [==============================] - 1s 654ms/step\n",
            "Epoch 237/500, Discriminator Loss: 0.0004800213500857353, Generator Loss: 0.0006686814595013857\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 238/500, Discriminator Loss: 0.0005261047190288082, Generator Loss: 0.0006702280370518565\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 239/500, Discriminator Loss: 0.0005618353025056422, Generator Loss: 0.0006551991682499647\n",
            "2/2 [==============================] - 1s 658ms/step\n",
            "Epoch 240/500, Discriminator Loss: 0.00047517026541754603, Generator Loss: 0.0006563070928677917\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 241/500, Discriminator Loss: 0.0005015530914533883, Generator Loss: 0.0006549835670739412\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 242/500, Discriminator Loss: 0.0005210865492699668, Generator Loss: 0.0006400635465979576\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 243/500, Discriminator Loss: 0.0005548802146222442, Generator Loss: 0.0006457091658376157\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 244/500, Discriminator Loss: 0.0004996847419533879, Generator Loss: 0.0006511870888061821\n",
            "2/2 [==============================] - 2s 933ms/step\n",
            "Epoch 245/500, Discriminator Loss: 0.0005172787787159905, Generator Loss: 0.0006435798713937402\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 246/500, Discriminator Loss: 0.0005330667190719396, Generator Loss: 0.0006495459238067269\n",
            "2/2 [==============================] - 1s 643ms/step\n",
            "Epoch 247/500, Discriminator Loss: 0.0005044839635957032, Generator Loss: 0.0006329800235107541\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 248/500, Discriminator Loss: 0.0004775338456965983, Generator Loss: 0.0006233929307200015\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 249/500, Discriminator Loss: 0.0004622837441274896, Generator Loss: 0.00063770089764148\n",
            "2/2 [==============================] - 1s 635ms/step\n",
            "Epoch 250/500, Discriminator Loss: 0.0004659728583646938, Generator Loss: 0.000635819393210113\n",
            "2/2 [==============================] - 2s 900ms/step\n",
            "Epoch 251/500, Discriminator Loss: 0.0004583890695357695, Generator Loss: 0.000645405612885952\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 252/500, Discriminator Loss: 0.00045464794675353914, Generator Loss: 0.0006534075364470482\n",
            "2/2 [==============================] - 1s 643ms/step\n",
            "Epoch 253/500, Discriminator Loss: 0.000555390288354829, Generator Loss: 0.0006509579252451658\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 254/500, Discriminator Loss: 0.0005220636376179755, Generator Loss: 0.0006518892478197813\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 255/500, Discriminator Loss: 0.0004629806790035218, Generator Loss: 0.0006633145967498422\n",
            "2/2 [==============================] - 1s 628ms/step\n",
            "Epoch 256/500, Discriminator Loss: 0.00044645574234891683, Generator Loss: 0.0006473834509961307\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 257/500, Discriminator Loss: 0.0005505449371412396, Generator Loss: 0.0006305889692157507\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 258/500, Discriminator Loss: 0.0006201441574376076, Generator Loss: 0.0006292334874160588\n",
            "2/2 [==============================] - 1s 631ms/step\n",
            "Epoch 259/500, Discriminator Loss: 0.0004704122547991574, Generator Loss: 0.0006309739546850324\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 260/500, Discriminator Loss: 0.0005183326720725745, Generator Loss: 0.0006348715396597981\n",
            "2/2 [==============================] - 1s 661ms/step\n",
            "Epoch 261/500, Discriminator Loss: 0.0005166386545170099, Generator Loss: 0.0006203360971994698\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 262/500, Discriminator Loss: 0.00041501042142044753, Generator Loss: 0.0006303929258137941\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 263/500, Discriminator Loss: 0.0005574843235081062, Generator Loss: 0.0006192720029503107\n",
            "2/2 [==============================] - 1s 658ms/step\n",
            "Epoch 264/500, Discriminator Loss: 0.0005016663781134412, Generator Loss: 0.0006264431867748499\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 265/500, Discriminator Loss: 0.0005189060029806569, Generator Loss: 0.0006234610918909311\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 266/500, Discriminator Loss: 0.0005593703826889396, Generator Loss: 0.0005991236539557576\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 267/500, Discriminator Loss: 0.0005150846554897726, Generator Loss: 0.0005960658891126513\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 268/500, Discriminator Loss: 0.0004764754994539544, Generator Loss: 0.0005830323789268732\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 269/500, Discriminator Loss: 0.0004742223536595702, Generator Loss: 0.0005886524450033903\n",
            "2/2 [==============================] - 1s 661ms/step\n",
            "Epoch 270/500, Discriminator Loss: 0.0005296581948641688, Generator Loss: 0.0005871074972674251\n",
            "2/2 [==============================] - 1s 654ms/step\n",
            "Epoch 271/500, Discriminator Loss: 0.00048717312165535986, Generator Loss: 0.0006051711388863623\n",
            "2/2 [==============================] - 1s 671ms/step\n",
            "Epoch 272/500, Discriminator Loss: 0.00040008672658586875, Generator Loss: 0.000625004933681339\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 273/500, Discriminator Loss: 0.0004642106650862843, Generator Loss: 0.000628730864264071\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 274/500, Discriminator Loss: 0.0004922482185065746, Generator Loss: 0.0006219677743501961\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 275/500, Discriminator Loss: 0.0005336303147487342, Generator Loss: 0.0006227277917787433\n",
            "2/2 [==============================] - 1s 642ms/step\n",
            "Epoch 276/500, Discriminator Loss: 0.0005837259814143181, Generator Loss: 0.0006386343156918883\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 277/500, Discriminator Loss: 0.0005206723144510761, Generator Loss: 0.0006246098782867193\n",
            "2/2 [==============================] - 1s 657ms/step\n",
            "Epoch 278/500, Discriminator Loss: 0.0005639486771542579, Generator Loss: 0.0006611848366446793\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 279/500, Discriminator Loss: 0.0005148237396497279, Generator Loss: 0.0006624620873481035\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 280/500, Discriminator Loss: 0.0006168246036395431, Generator Loss: 0.000679998192936182\n",
            "2/2 [==============================] - 1s 657ms/step\n",
            "Epoch 281/500, Discriminator Loss: 0.0006283469119807705, Generator Loss: 0.0006942999316379428\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 282/500, Discriminator Loss: 0.0006364546861732379, Generator Loss: 0.0007331609958782792\n",
            "2/2 [==============================] - 1s 779ms/step\n",
            "Epoch 283/500, Discriminator Loss: 0.0005914436478633434, Generator Loss: 0.0007235439261421561\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 284/500, Discriminator Loss: 0.0005877118819626048, Generator Loss: 0.0006854477105662227\n",
            "2/2 [==============================] - 2s 891ms/step\n",
            "Epoch 285/500, Discriminator Loss: 0.0005773551092715934, Generator Loss: 0.0006625292007811368\n",
            "2/2 [==============================] - 1s 642ms/step\n",
            "Epoch 286/500, Discriminator Loss: 0.0006115919095464051, Generator Loss: 0.0006929095252417028\n",
            "2/2 [==============================] - 1s 642ms/step\n",
            "Epoch 287/500, Discriminator Loss: 0.0005421908281277865, Generator Loss: 0.0007162935798987746\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 288/500, Discriminator Loss: 0.0006205657846294343, Generator Loss: 0.0006831124192103744\n",
            "2/2 [==============================] - 1s 641ms/step\n",
            "Epoch 289/500, Discriminator Loss: 0.0006539283494930714, Generator Loss: 0.0006865545874461532\n",
            "2/2 [==============================] - 2s 826ms/step\n",
            "Epoch 290/500, Discriminator Loss: 0.0007146544521674514, Generator Loss: 0.0006943796179257333\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 291/500, Discriminator Loss: 0.0007190975593402982, Generator Loss: 0.0007443804061040282\n",
            "2/2 [==============================] - 1s 630ms/step\n",
            "Epoch 292/500, Discriminator Loss: 0.0005798617785330862, Generator Loss: 0.0007738530985079706\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 293/500, Discriminator Loss: 0.000642596889520064, Generator Loss: 0.0007878320757299662\n",
            "2/2 [==============================] - 1s 664ms/step\n",
            "Epoch 294/500, Discriminator Loss: 0.0008843863033689559, Generator Loss: 0.0008000616217032075\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 295/500, Discriminator Loss: 0.0005752846191171557, Generator Loss: 0.000828287098556757\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 296/500, Discriminator Loss: 0.0006631541618844494, Generator Loss: 0.0008246611105278134\n",
            "2/2 [==============================] - 1s 632ms/step\n",
            "Epoch 297/500, Discriminator Loss: 0.000617985861026682, Generator Loss: 0.0009013507515192032\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 298/500, Discriminator Loss: 0.0006663091480731964, Generator Loss: 0.0008849459700286388\n",
            "2/2 [==============================] - 2s 844ms/step\n",
            "Epoch 299/500, Discriminator Loss: 0.000657405355013907, Generator Loss: 0.0009309084853157401\n",
            "2/2 [==============================] - 1s 625ms/step\n",
            "Epoch 300/500, Discriminator Loss: 0.000687174586346373, Generator Loss: 0.000936181633733213\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 301/500, Discriminator Loss: 0.0007438978645950556, Generator Loss: 0.0009647796396166086\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 302/500, Discriminator Loss: 0.000664158898871392, Generator Loss: 0.001040272181853652\n",
            "2/2 [==============================] - 1s 643ms/step\n",
            "Epoch 303/500, Discriminator Loss: 0.000844672933453694, Generator Loss: 0.0010309047065675259\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 304/500, Discriminator Loss: 0.0007387830119114369, Generator Loss: 0.001013398403301835\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 305/500, Discriminator Loss: 0.0007545537519035861, Generator Loss: 0.0011269806418567896\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 306/500, Discriminator Loss: 0.0007021513010840863, Generator Loss: 0.0011571027571335435\n",
            "2/2 [==============================] - 1s 662ms/step\n",
            "Epoch 307/500, Discriminator Loss: 0.0007832232513464987, Generator Loss: 0.001147446921095252\n",
            "2/2 [==============================] - 1s 638ms/step\n",
            "Epoch 308/500, Discriminator Loss: 0.0007553760951850563, Generator Loss: 0.0011383297387510538\n",
            "2/2 [==============================] - 1s 642ms/step\n",
            "Epoch 309/500, Discriminator Loss: 0.0007457708998117596, Generator Loss: 0.0011315997689962387\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 310/500, Discriminator Loss: 0.000794006627984345, Generator Loss: 0.001261939643882215\n",
            "2/2 [==============================] - 2s 956ms/step\n",
            "Epoch 311/500, Discriminator Loss: 0.0008041422697715461, Generator Loss: 0.0013395927380770445\n",
            "2/2 [==============================] - 1s 667ms/step\n",
            "Epoch 312/500, Discriminator Loss: 0.000913661380764097, Generator Loss: 0.0013465770753100514\n",
            "2/2 [==============================] - 1s 667ms/step\n",
            "Epoch 313/500, Discriminator Loss: 0.0008472578774672002, Generator Loss: 0.0012845011660829186\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 314/500, Discriminator Loss: 0.00126221778918989, Generator Loss: 0.001282078679651022\n",
            "2/2 [==============================] - 1s 668ms/step\n",
            "Epoch 315/500, Discriminator Loss: 0.0008500365074723959, Generator Loss: 0.0012242959346622229\n",
            "2/2 [==============================] - 1s 667ms/step\n",
            "Epoch 316/500, Discriminator Loss: 0.0009548146917950362, Generator Loss: 0.0011684733908623457\n",
            "2/2 [==============================] - 1s 757ms/step\n",
            "Epoch 317/500, Discriminator Loss: 0.0009107769292313606, Generator Loss: 0.0011029079323634505\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 318/500, Discriminator Loss: 0.0011618155986070633, Generator Loss: 0.0009697468485683203\n",
            "2/2 [==============================] - 1s 655ms/step\n",
            "Epoch 319/500, Discriminator Loss: 0.0008322494686581194, Generator Loss: 0.0009725421550683677\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 320/500, Discriminator Loss: 0.0009307668078690767, Generator Loss: 0.000924862630199641\n",
            "2/2 [==============================] - 1s 642ms/step\n",
            "Epoch 321/500, Discriminator Loss: 0.0005621342570520937, Generator Loss: 0.0008797615300863981\n",
            "2/2 [==============================] - 1s 661ms/step\n",
            "Epoch 322/500, Discriminator Loss: 0.0006007129995850846, Generator Loss: 0.0007759755244478583\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 323/500, Discriminator Loss: 0.000774398329667747, Generator Loss: 0.0007461912464350462\n",
            "2/2 [==============================] - 1s 641ms/step\n",
            "Epoch 324/500, Discriminator Loss: 0.0006667332490906119, Generator Loss: 0.0007466613897122443\n",
            "2/2 [==============================] - 1s 637ms/step\n",
            "Epoch 325/500, Discriminator Loss: 0.0006732515175826848, Generator Loss: 0.0006835739477537572\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 326/500, Discriminator Loss: 0.0007270541391335428, Generator Loss: 0.0006716542993672192\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 327/500, Discriminator Loss: 0.0006345422007143497, Generator Loss: 0.0007107516285032034\n",
            "2/2 [==============================] - 1s 675ms/step\n",
            "Epoch 328/500, Discriminator Loss: 0.0005849225271958858, Generator Loss: 0.0007283189333975315\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 329/500, Discriminator Loss: 0.0006416032847482711, Generator Loss: 0.0006931672687642276\n",
            "2/2 [==============================] - 1s 635ms/step\n",
            "Epoch 330/500, Discriminator Loss: 0.0008349422423634678, Generator Loss: 0.0007042789366096258\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 331/500, Discriminator Loss: 0.0006431456713471562, Generator Loss: 0.0006893593235872686\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 332/500, Discriminator Loss: 0.0006880845176056027, Generator Loss: 0.000663670536596328\n",
            "2/2 [==============================] - 1s 664ms/step\n",
            "Epoch 333/500, Discriminator Loss: 0.0005799450591439381, Generator Loss: 0.0006631914293393493\n",
            "2/2 [==============================] - 1s 665ms/step\n",
            "Epoch 334/500, Discriminator Loss: 0.000659574696328491, Generator Loss: 0.0006382944993674755\n",
            "2/2 [==============================] - 2s 998ms/step\n",
            "Epoch 335/500, Discriminator Loss: 0.0007010043773334473, Generator Loss: 0.0005995059036649764\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 336/500, Discriminator Loss: 0.0006121646147221327, Generator Loss: 0.0006020144792273641\n",
            "2/2 [==============================] - 1s 657ms/step\n",
            "Epoch 337/500, Discriminator Loss: 0.0008430501038674265, Generator Loss: 0.0005793919553980231\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 338/500, Discriminator Loss: 0.0006829660560470074, Generator Loss: 0.0005814040778204799\n",
            "2/2 [==============================] - 1s 631ms/step\n",
            "Epoch 339/500, Discriminator Loss: 0.0006302102410700172, Generator Loss: 0.0005598684656433761\n",
            "2/2 [==============================] - 1s 664ms/step\n",
            "Epoch 340/500, Discriminator Loss: 0.0005672071274602786, Generator Loss: 0.0005267465021461248\n",
            "2/2 [==============================] - 2s 895ms/step\n",
            "Epoch 341/500, Discriminator Loss: 0.0005382619128795341, Generator Loss: 0.0005007641739211977\n",
            "2/2 [==============================] - 1s 635ms/step\n",
            "Epoch 342/500, Discriminator Loss: 0.0005804981046821922, Generator Loss: 0.00046838258276693523\n",
            "2/2 [==============================] - 1s 662ms/step\n",
            "Epoch 343/500, Discriminator Loss: 0.0006546555378008634, Generator Loss: 0.00043971228296868503\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 344/500, Discriminator Loss: 0.0004913130542263389, Generator Loss: 0.00043556507444009185\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 345/500, Discriminator Loss: 0.000652773684123531, Generator Loss: 0.00042439199751242995\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 346/500, Discriminator Loss: 0.0004959504294674844, Generator Loss: 0.0004101620288565755\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 347/500, Discriminator Loss: 0.0006421824509743601, Generator Loss: 0.0003664529067464173\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 348/500, Discriminator Loss: 0.0006561707414221019, Generator Loss: 0.0003685664851218462\n",
            "2/2 [==============================] - 2s 756ms/step\n",
            "Epoch 349/500, Discriminator Loss: 0.0005173834506422281, Generator Loss: 0.000377535296138376\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 350/500, Discriminator Loss: 0.00056330012739636, Generator Loss: 0.00036472230567596853\n",
            "2/2 [==============================] - 1s 638ms/step\n",
            "Epoch 351/500, Discriminator Loss: 0.000593367381952703, Generator Loss: 0.0003347178571857512\n",
            "2/2 [==============================] - 1s 675ms/step\n",
            "Epoch 352/500, Discriminator Loss: 0.0005511523631867021, Generator Loss: 0.0003375910746399313\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 353/500, Discriminator Loss: 0.0004721556615550071, Generator Loss: 0.00034328323090448976\n",
            "2/2 [==============================] - 1s 637ms/step\n",
            "Epoch 354/500, Discriminator Loss: 0.0005265532818157226, Generator Loss: 0.0003304696874693036\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 355/500, Discriminator Loss: 0.0005095073865959421, Generator Loss: 0.0003270791785325855\n",
            "2/2 [==============================] - 2s 883ms/step\n",
            "Epoch 356/500, Discriminator Loss: 0.0004923990345560014, Generator Loss: 0.0003299385716672987\n",
            "2/2 [==============================] - 1s 670ms/step\n",
            "Epoch 357/500, Discriminator Loss: 0.000374931885744445, Generator Loss: 0.00034627484274096787\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 358/500, Discriminator Loss: 0.0005078436661278829, Generator Loss: 0.00032399309566244483\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 359/500, Discriminator Loss: 0.00039979437133297324, Generator Loss: 0.0003158576728310436\n",
            "2/2 [==============================] - 1s 653ms/step\n",
            "Epoch 360/500, Discriminator Loss: 0.00036872533382847905, Generator Loss: 0.00032102700788527727\n",
            "2/2 [==============================] - 1s 665ms/step\n",
            "Epoch 361/500, Discriminator Loss: 0.00044702543527819216, Generator Loss: 0.00032287469366565347\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 362/500, Discriminator Loss: 0.0004370246606413275, Generator Loss: 0.00032122916309162974\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 363/500, Discriminator Loss: 0.00047749858640599996, Generator Loss: 0.00034159430651925504\n",
            "2/2 [==============================] - 1s 654ms/step\n",
            "Epoch 364/500, Discriminator Loss: 0.0004344283079262823, Generator Loss: 0.00035580553230829537\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 365/500, Discriminator Loss: 0.0004452416906133294, Generator Loss: 0.0003613007429521531\n",
            "2/2 [==============================] - 1s 676ms/step\n",
            "Epoch 366/500, Discriminator Loss: 0.0005038302333559841, Generator Loss: 0.0003709640586748719\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 367/500, Discriminator Loss: 0.0004571280878735706, Generator Loss: 0.00038030208088457584\n",
            "2/2 [==============================] - 1s 670ms/step\n",
            "Epoch 368/500, Discriminator Loss: 0.0006364058353938162, Generator Loss: 0.0004051709547638893\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 369/500, Discriminator Loss: 0.0004497752961469814, Generator Loss: 0.0004202749114483595\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 370/500, Discriminator Loss: 0.00048358111234847456, Generator Loss: 0.00041633250657469034\n",
            "2/2 [==============================] - 1s 647ms/step\n",
            "Epoch 371/500, Discriminator Loss: 0.0010375961137469858, Generator Loss: 0.00038617680547758937\n",
            "2/2 [==============================] - 1s 639ms/step\n",
            "Epoch 372/500, Discriminator Loss: 0.000532019286765717, Generator Loss: 0.00038797082379460335\n",
            "2/2 [==============================] - 1s 769ms/step\n",
            "Epoch 373/500, Discriminator Loss: 0.0006123640341684222, Generator Loss: 0.0004060867358930409\n",
            "2/2 [==============================] - 1s 665ms/step\n",
            "Epoch 374/500, Discriminator Loss: 0.0005118336412124336, Generator Loss: 0.00046469777589663863\n",
            "2/2 [==============================] - 1s 657ms/step\n",
            "Epoch 375/500, Discriminator Loss: 0.0005902917764615268, Generator Loss: 0.0004697933909483254\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 376/500, Discriminator Loss: 0.0005332070286385715, Generator Loss: 0.00048462310223840177\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 377/500, Discriminator Loss: 0.0005075240915175527, Generator Loss: 0.0005330781568773091\n",
            "2/2 [==============================] - 1s 669ms/step\n",
            "Epoch 378/500, Discriminator Loss: 0.0005827316344948485, Generator Loss: 0.0005576597759500146\n",
            "2/2 [==============================] - 2s 936ms/step\n",
            "Epoch 379/500, Discriminator Loss: 0.0005739151529269293, Generator Loss: 0.0006335164653137326\n",
            "2/2 [==============================] - 1s 658ms/step\n",
            "Epoch 380/500, Discriminator Loss: 0.0005288605025270954, Generator Loss: 0.0006596219027414918\n",
            "2/2 [==============================] - 1s 655ms/step\n",
            "Epoch 381/500, Discriminator Loss: 0.0006396735698217526, Generator Loss: 0.0006939373561181128\n",
            "2/2 [==============================] - 1s 675ms/step\n",
            "Epoch 382/500, Discriminator Loss: 0.0006886515184305608, Generator Loss: 0.0008225928759202361\n",
            "2/2 [==============================] - 1s 657ms/step\n",
            "Epoch 383/500, Discriminator Loss: 0.0005410929443314672, Generator Loss: 0.0009820194682106376\n",
            "2/2 [==============================] - 2s 939ms/step\n",
            "Epoch 384/500, Discriminator Loss: 0.001157103688456118, Generator Loss: 0.0033721420913934708\n",
            "2/2 [==============================] - 1s 667ms/step\n",
            "Epoch 385/500, Discriminator Loss: 0.00030767862699576654, Generator Loss: 4.52533483505249\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 386/500, Discriminator Loss: 0.0002806230986607261, Generator Loss: 26.0887451171875\n",
            "2/2 [==============================] - 2s 639ms/step\n",
            "Epoch 387/500, Discriminator Loss: 0.0002448197847115807, Generator Loss: 18.596975326538086\n",
            "2/2 [==============================] - 1s 672ms/step\n",
            "Epoch 388/500, Discriminator Loss: 0.0003730850148713216, Generator Loss: 7.533170223236084\n",
            "2/2 [==============================] - 1s 668ms/step\n",
            "Epoch 389/500, Discriminator Loss: 0.00032050881418399513, Generator Loss: 7.084718704223633\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 390/500, Discriminator Loss: 0.001667985343374312, Generator Loss: 4.752207279205322\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 391/500, Discriminator Loss: 0.0002606623993415269, Generator Loss: 3.8078324794769287\n",
            "2/2 [==============================] - 1s 638ms/step\n",
            "Epoch 392/500, Discriminator Loss: 0.00038018805207684636, Generator Loss: 1.842362880706787\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 393/500, Discriminator Loss: 0.0004644309447030537, Generator Loss: 0.4869639277458191\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 394/500, Discriminator Loss: 0.0001567262397657032, Generator Loss: 0.1455479860305786\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 395/500, Discriminator Loss: 0.000176275112607982, Generator Loss: 0.06719540804624557\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 396/500, Discriminator Loss: 0.0001816486728785094, Generator Loss: 0.042605672031641006\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 397/500, Discriminator Loss: 0.00016413875709986314, Generator Loss: 0.027901988476514816\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 398/500, Discriminator Loss: 0.00010739277786342427, Generator Loss: 0.019471291452646255\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 399/500, Discriminator Loss: 0.00019060700560658006, Generator Loss: 0.01419852301478386\n",
            "2/2 [==============================] - 1s 655ms/step\n",
            "Epoch 400/500, Discriminator Loss: 0.00012722074734483613, Generator Loss: 0.010980656370520592\n",
            "2/2 [==============================] - 1s 653ms/step\n",
            "Epoch 401/500, Discriminator Loss: 0.00011847876976389671, Generator Loss: 0.008863415569067001\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 402/500, Discriminator Loss: 0.00014427957466978114, Generator Loss: 0.0068906573578715324\n",
            "2/2 [==============================] - 1s 668ms/step\n",
            "Epoch 403/500, Discriminator Loss: 0.00011777392228395911, Generator Loss: 0.005475690122693777\n",
            "2/2 [==============================] - 1s 653ms/step\n",
            "Epoch 404/500, Discriminator Loss: 9.370650695927907e-05, Generator Loss: 0.004584088921546936\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 405/500, Discriminator Loss: 0.00010401658437331207, Generator Loss: 0.003796063829213381\n",
            "2/2 [==============================] - 1s 633ms/step\n",
            "Epoch 406/500, Discriminator Loss: 8.811280258669285e-05, Generator Loss: 0.0032370537519454956\n",
            "2/2 [==============================] - 1s 654ms/step\n",
            "Epoch 407/500, Discriminator Loss: 8.9042467152467e-05, Generator Loss: 0.0028924942016601562\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 408/500, Discriminator Loss: 8.607330710219685e-05, Generator Loss: 0.0025009955279529095\n",
            "2/2 [==============================] - 1s 664ms/step\n",
            "Epoch 409/500, Discriminator Loss: 0.00021817292235937202, Generator Loss: 0.002384232124313712\n",
            "2/2 [==============================] - 1s 674ms/step\n",
            "Epoch 410/500, Discriminator Loss: 9.221291293215472e-05, Generator Loss: 0.0021377364173531532\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 411/500, Discriminator Loss: 0.00010882267270062584, Generator Loss: 0.0019040243932977319\n",
            "2/2 [==============================] - 1s 661ms/step\n",
            "Epoch 412/500, Discriminator Loss: 0.00012152429371781182, Generator Loss: 0.0016167624853551388\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 413/500, Discriminator Loss: 7.575765175715787e-05, Generator Loss: 0.001437772181816399\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 414/500, Discriminator Loss: 6.938061505934456e-05, Generator Loss: 0.0012633726000785828\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 415/500, Discriminator Loss: 7.847819324524608e-05, Generator Loss: 0.0011380002833902836\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 416/500, Discriminator Loss: 6.918812687217724e-05, Generator Loss: 0.00100516842212528\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 417/500, Discriminator Loss: 0.00015529861411778256, Generator Loss: 0.0008819577051326632\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 418/500, Discriminator Loss: 9.822756874200422e-05, Generator Loss: 0.0007811345858499408\n",
            "2/2 [==============================] - 1s 655ms/step\n",
            "Epoch 419/500, Discriminator Loss: 8.726746455067769e-05, Generator Loss: 0.0007190060568973422\n",
            "2/2 [==============================] - 1s 654ms/step\n",
            "Epoch 420/500, Discriminator Loss: 7.67556884966325e-05, Generator Loss: 0.0006518962327390909\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 421/500, Discriminator Loss: 6.372879761329386e-05, Generator Loss: 0.000591509451624006\n",
            "2/2 [==============================] - 1s 672ms/step\n",
            "Epoch 422/500, Discriminator Loss: 5.358250746212434e-05, Generator Loss: 0.0005455561331473291\n",
            "2/2 [==============================] - 1s 787ms/step\n",
            "Epoch 423/500, Discriminator Loss: 0.0001035012519423617, Generator Loss: 0.0004971894668415189\n",
            "2/2 [==============================] - 1s 662ms/step\n",
            "Epoch 424/500, Discriminator Loss: 6.627227958233561e-05, Generator Loss: 0.000449156214017421\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "Epoch 425/500, Discriminator Loss: 6.193451190483756e-05, Generator Loss: 0.00040528966928832233\n",
            "2/2 [==============================] - 1s 665ms/step\n",
            "Epoch 426/500, Discriminator Loss: 6.631789437960833e-05, Generator Loss: 0.00037077051820233464\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 427/500, Discriminator Loss: 8.580855137552135e-05, Generator Loss: 0.00033630384132266045\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 428/500, Discriminator Loss: 6.945746827113908e-05, Generator Loss: 0.00030718586640432477\n",
            "2/2 [==============================] - 1s 636ms/step\n",
            "Epoch 429/500, Discriminator Loss: 4.72790170533699e-05, Generator Loss: 0.00028211771859787405\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 430/500, Discriminator Loss: 5.874902581126662e-05, Generator Loss: 0.00026023577083833516\n",
            "2/2 [==============================] - 1s 638ms/step\n",
            "Epoch 431/500, Discriminator Loss: 7.746267237962456e-05, Generator Loss: 0.00024524290347471833\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 432/500, Discriminator Loss: 6.824864431109745e-05, Generator Loss: 0.00022581385564990342\n",
            "2/2 [==============================] - 2s 651ms/step\n",
            "Epoch 433/500, Discriminator Loss: 5.717300155083649e-05, Generator Loss: 0.00021232347353361547\n",
            "2/2 [==============================] - 1s 633ms/step\n",
            "Epoch 434/500, Discriminator Loss: 5.277158197714016e-05, Generator Loss: 0.000196225504623726\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 435/500, Discriminator Loss: 8.509572035109159e-05, Generator Loss: 0.0001814820134313777\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 436/500, Discriminator Loss: 9.440372014068998e-05, Generator Loss: 0.0001716107944957912\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 437/500, Discriminator Loss: 6.674500946246553e-05, Generator Loss: 0.00016027074889279902\n",
            "2/2 [==============================] - 1s 666ms/step\n",
            "Epoch 438/500, Discriminator Loss: 7.737034138699528e-05, Generator Loss: 0.0001505778345745057\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 439/500, Discriminator Loss: 6.991536793066189e-05, Generator Loss: 0.00014254107372835279\n",
            "2/2 [==============================] - 1s 666ms/step\n",
            "Epoch 440/500, Discriminator Loss: 4.5674480134039186e-05, Generator Loss: 0.00013310505892150104\n",
            "2/2 [==============================] - 1s 677ms/step\n",
            "Epoch 441/500, Discriminator Loss: 4.887789691565558e-05, Generator Loss: 0.00012545837671495974\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 442/500, Discriminator Loss: 8.202253411582205e-05, Generator Loss: 0.00012031320511596277\n",
            "2/2 [==============================] - 1s 650ms/step\n",
            "Epoch 443/500, Discriminator Loss: 5.742833855038043e-05, Generator Loss: 0.00011644134792732075\n",
            "2/2 [==============================] - 1s 642ms/step\n",
            "Epoch 444/500, Discriminator Loss: 6.237299021449871e-05, Generator Loss: 0.00010833328269654885\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 445/500, Discriminator Loss: 6.79042968840804e-05, Generator Loss: 0.0001027081671054475\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 446/500, Discriminator Loss: 4.590508615365252e-05, Generator Loss: 9.769239841261879e-05\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 447/500, Discriminator Loss: 4.886517854174599e-05, Generator Loss: 9.548247908242047e-05\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 448/500, Discriminator Loss: 6.542551636812277e-05, Generator Loss: 9.181453788187355e-05\n",
            "2/2 [==============================] - 1s 658ms/step\n",
            "Epoch 449/500, Discriminator Loss: 9.704880176286679e-05, Generator Loss: 9.092817344935611e-05\n",
            "2/2 [==============================] - 1s 643ms/step\n",
            "Epoch 450/500, Discriminator Loss: 6.38478304608725e-05, Generator Loss: 8.705531945452094e-05\n",
            "2/2 [==============================] - 1s 658ms/step\n",
            "Epoch 451/500, Discriminator Loss: 5.893983870919328e-05, Generator Loss: 8.434402116108686e-05\n",
            "2/2 [==============================] - 1s 642ms/step\n",
            "Epoch 452/500, Discriminator Loss: 7.803920379956253e-05, Generator Loss: 8.234969573095441e-05\n",
            "2/2 [==============================] - 1s 640ms/step\n",
            "Epoch 453/500, Discriminator Loss: 9.449326898902655e-05, Generator Loss: 8.098655234789476e-05\n",
            "2/2 [==============================] - 1s 631ms/step\n",
            "Epoch 454/500, Discriminator Loss: 7.61891897127498e-05, Generator Loss: 8.105354208964854e-05\n",
            "2/2 [==============================] - 1s 655ms/step\n",
            "Epoch 455/500, Discriminator Loss: 6.652770025539212e-05, Generator Loss: 7.981673115864396e-05\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 456/500, Discriminator Loss: 6.032833334757015e-05, Generator Loss: 7.91907514212653e-05\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 457/500, Discriminator Loss: 7.559882942587137e-05, Generator Loss: 7.970469596330076e-05\n",
            "2/2 [==============================] - 1s 654ms/step\n",
            "Epoch 458/500, Discriminator Loss: 5.259777026367374e-05, Generator Loss: 7.871263369452208e-05\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 459/500, Discriminator Loss: 8.115446689771488e-05, Generator Loss: 7.765766349621117e-05\n",
            "2/2 [==============================] - 1s 637ms/step\n",
            "Epoch 460/500, Discriminator Loss: 8.092841017059982e-05, Generator Loss: 7.692891813348979e-05\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 461/500, Discriminator Loss: 6.871737059555016e-05, Generator Loss: 7.660436676815152e-05\n",
            "2/2 [==============================] - 1s 668ms/step\n",
            "Epoch 462/500, Discriminator Loss: 8.981608698377386e-05, Generator Loss: 7.55192304495722e-05\n",
            "2/2 [==============================] - 1s 637ms/step\n",
            "Epoch 463/500, Discriminator Loss: 7.469373304047622e-05, Generator Loss: 7.748747884761542e-05\n",
            "2/2 [==============================] - 1s 637ms/step\n",
            "Epoch 464/500, Discriminator Loss: 7.839175304980017e-05, Generator Loss: 7.791789539624006e-05\n",
            "2/2 [==============================] - 1s 634ms/step\n",
            "Epoch 465/500, Discriminator Loss: 8.651426469441503e-05, Generator Loss: 7.703824667260051e-05\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 466/500, Discriminator Loss: 7.434293365804479e-05, Generator Loss: 7.747257768642157e-05\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 467/500, Discriminator Loss: 6.854720413684845e-05, Generator Loss: 7.789638766553253e-05\n",
            "2/2 [==============================] - 2s 897ms/step\n",
            "Epoch 468/500, Discriminator Loss: 7.5365122029325e-05, Generator Loss: 7.956582703627646e-05\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 469/500, Discriminator Loss: 0.00011132756117149256, Generator Loss: 8.246046490967274e-05\n",
            "2/2 [==============================] - 1s 680ms/step\n",
            "Epoch 470/500, Discriminator Loss: 7.328519131988287e-05, Generator Loss: 8.40297361719422e-05\n",
            "2/2 [==============================] - 2s 933ms/step\n",
            "Epoch 471/500, Discriminator Loss: 9.839630001806654e-05, Generator Loss: 8.525616431143135e-05\n",
            "2/2 [==============================] - 1s 665ms/step\n",
            "Epoch 472/500, Discriminator Loss: 8.681081817485392e-05, Generator Loss: 8.779273775871843e-05\n",
            "2/2 [==============================] - 1s 649ms/step\n",
            "Epoch 473/500, Discriminator Loss: 7.872302012401633e-05, Generator Loss: 8.950655319495127e-05\n",
            "2/2 [==============================] - 1s 659ms/step\n",
            "Epoch 474/500, Discriminator Loss: 9.350151231046766e-05, Generator Loss: 9.226032125297934e-05\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "Epoch 475/500, Discriminator Loss: 8.551698556402698e-05, Generator Loss: 9.4197916041594e-05\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 476/500, Discriminator Loss: 0.00010004586147260852, Generator Loss: 9.963128832168877e-05\n",
            "2/2 [==============================] - 1s 670ms/step\n",
            "Epoch 477/500, Discriminator Loss: 8.834098116494715e-05, Generator Loss: 0.00010665399167919531\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 478/500, Discriminator Loss: 8.333064033649862e-05, Generator Loss: 0.00011136144166812301\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 479/500, Discriminator Loss: 8.330481796292588e-05, Generator Loss: 0.000117488692922052\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 480/500, Discriminator Loss: 8.875191997503862e-05, Generator Loss: 0.00012701022205874324\n",
            "2/2 [==============================] - 1s 673ms/step\n",
            "Epoch 481/500, Discriminator Loss: 8.693173731444404e-05, Generator Loss: 0.00013664158177562058\n",
            "2/2 [==============================] - 1s 658ms/step\n",
            "Epoch 482/500, Discriminator Loss: 0.00011853555042762309, Generator Loss: 0.00014425721019506454\n",
            "2/2 [==============================] - 1s 644ms/step\n",
            "Epoch 483/500, Discriminator Loss: 0.00010506672333576716, Generator Loss: 0.00015240949869621545\n",
            "2/2 [==============================] - 1s 655ms/step\n",
            "Epoch 484/500, Discriminator Loss: 9.776782462722622e-05, Generator Loss: 0.00016451836563646793\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 485/500, Discriminator Loss: 9.929818770615384e-05, Generator Loss: 0.00018332074978388846\n",
            "2/2 [==============================] - 1s 648ms/step\n",
            "Epoch 486/500, Discriminator Loss: 0.00010481146455276757, Generator Loss: 0.00019702399731613696\n",
            "2/2 [==============================] - 1s 645ms/step\n",
            "Epoch 487/500, Discriminator Loss: 8.70473450049758e-05, Generator Loss: 0.00021106839994899929\n",
            "2/2 [==============================] - 1s 635ms/step\n",
            "Epoch 488/500, Discriminator Loss: 0.00010039604967460036, Generator Loss: 0.00022502544743474573\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 489/500, Discriminator Loss: 9.718351066112518e-05, Generator Loss: 0.00024239100457634777\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 490/500, Discriminator Loss: 0.00013041564307059161, Generator Loss: 0.0002564909518696368\n",
            "2/2 [==============================] - 1s 654ms/step\n",
            "Epoch 491/500, Discriminator Loss: 0.00010503900557523593, Generator Loss: 0.00026972650084644556\n",
            "2/2 [==============================] - 2s 657ms/step\n",
            "Epoch 492/500, Discriminator Loss: 0.0001142207911470905, Generator Loss: 0.000295549922157079\n",
            "2/2 [==============================] - 1s 652ms/step\n",
            "Epoch 493/500, Discriminator Loss: 0.00011062770136049949, Generator Loss: 0.00031773815862834454\n",
            "2/2 [==============================] - 1s 655ms/step\n",
            "Epoch 494/500, Discriminator Loss: 9.115129796555266e-05, Generator Loss: 0.0003460110165178776\n",
            "2/2 [==============================] - 2s 1s/step\n",
            "Epoch 495/500, Discriminator Loss: 0.00011742213973775506, Generator Loss: 0.00036971320514567196\n",
            "2/2 [==============================] - 1s 641ms/step\n",
            "Epoch 496/500, Discriminator Loss: 9.475698607275262e-05, Generator Loss: 0.0004128332366235554\n",
            "2/2 [==============================] - 1s 666ms/step\n",
            "Epoch 497/500, Discriminator Loss: 0.00011845980770885944, Generator Loss: 0.0004352183314040303\n",
            "2/2 [==============================] - 2s 937ms/step\n",
            "Epoch 498/500, Discriminator Loss: 0.00012483172758948058, Generator Loss: 0.00046009442303329706\n",
            "2/2 [==============================] - 1s 656ms/step\n",
            "Epoch 499/500, Discriminator Loss: 0.00010723029481596313, Generator Loss: 0.0004889682168141007\n",
            "2/2 [==============================] - 1s 644ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 500/500, Discriminator Loss: 0.00010848306192201562, Generator Loss: 0.0005429548909887671\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, optimizers\n",
        "\n",
        "# Load the segmented images dataset with resizing\n",
        "def load_segmented_images_dataset(folder_path, target_size=(64, 64)):\n",
        "    segmented_images = []\n",
        "    for image_file in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        if image_file.endswith('.jpg') or image_file.endswith('.png'):\n",
        "            image = tf.keras.preprocessing.image.load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image) / 255.0  # Normalize pixel values\n",
        "            segmented_images.append(image)\n",
        "    return np.array(segmented_images)\n",
        "\n",
        "\n",
        "# Define the paths to your segmented images dataset\n",
        "segmented_images_folder = \"/content/drive/MyDrive/Project3/SegmentedImages\"\n",
        "\n",
        "# Load the segmented images dataset\n",
        "segmented_images = load_segmented_images_dataset(segmented_images_folder)\n",
        "\n",
        "# Define the input shape for the generator\n",
        "input_shape = segmented_images[0].shape\n",
        "\n",
        "# Build the generator, discriminator, and GAN models (using the code from the previous steps)\n",
        "generator = build_generator(input_shape)\n",
        "discriminator = build_discriminator(input_shape)\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator.compile(optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Freeze the discriminator's weights during GAN training\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Build the GAN model\n",
        "gan_input = layers.Input(shape=input_shape)\n",
        "generated_image = generator(gan_input)\n",
        "gan_output = discriminator(generated_image)\n",
        "gan = models.Model(gan_input, gan_output)\n",
        "\n",
        "# Compile the GAN model\n",
        "gan.compile(optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
        "            loss='binary_crossentropy')\n",
        "\n",
        "# Define the batch size and number of epochs for training\n",
        "batch_size = 64\n",
        "epochs = 500  # Adjust as needed\n",
        "\n",
        "# Define labels for real and fake images\n",
        "real_labels = np.ones((batch_size, 1))\n",
        "fake_labels = np.zeros((batch_size, 1))\n",
        "\n",
        "# Start training the GAN model\n",
        "for epoch in range(epochs):\n",
        "    # Train the discriminator\n",
        "    # Sample a batch of real images\n",
        "    real_images = segmented_images[np.random.randint(0, segmented_images.shape[0], batch_size)]\n",
        "    # Generate a batch of fake images\n",
        "    noise = np.random.normal(0, 1, (batch_size, *input_shape))\n",
        "    generated_images = generator.predict(noise)\n",
        "    # Train the discriminator with real and fake images\n",
        "    discriminator_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "    discriminator_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
        "    discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "\n",
        "    # Train the generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, *input_shape))\n",
        "    generator_loss = gan.train_on_batch(noise, real_labels)\n",
        "\n",
        "    # Print training progress\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {generator_loss}\")\n",
        "\n",
        "# Save the trained generator model\n",
        "generator.save(\"/content/drive/MyDrive/Project3/trained_generator_model.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3tF6IVqgF49"
      },
      "source": [
        "## **Minority Selection**\n",
        "After training the model with segmented images ,we call the model to generate the non tumorous images.The generated images are saved as Generated Images\n",
        "These are the Generated Images through GAN.\n",
        "https://drive.google.com/drive/folders/1AzRESPCXzEtT8EPJDlhq1gVqeuo96rN_?usp=drive_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBU4IlagqSZy",
        "outputId": "f2396ba9-9c6c-4094-83cc-237e3de2cd0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 560ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Generated images saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained generator model\n",
        "generator = load_model(\"/content/drive/MyDrive/Project3/trained_generator_model.h5\")\n",
        "\n",
        "# Generate non-tumorous MRI images\n",
        "num_images = 60\n",
        "input_shape = (64, 64, 1)\n",
        "generated_images = []\n",
        "for _ in range(num_images):\n",
        "    noise = np.random.normal(0, 1, (1, *input_shape))\n",
        "    generated_image = generator.predict(noise)\n",
        "    generated_images.append(generated_image)\n",
        "\n",
        "# Convert generated images to numpy array\n",
        "generated_images = np.array(generated_images)\n",
        "\n",
        "# Create a folder to save the generated images\n",
        "output_folder = \"/content/drive/MyDrive/Project3/GeneratedImages\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Save the generated images in the output folder\n",
        "for i, image in enumerate(generated_images):\n",
        "    output_path = os.path.join(output_folder, f\"generated_image_{i+1}.png\")\n",
        "    tf.keras.preprocessing.image.save_img(output_path, image[0])  # Selecting the first element to remove extra dimension\n",
        "\n",
        "print(\"Generated images saved successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LGz6yEtgtt4"
      },
      "source": [
        "## **Augmentation of Dataset**\n",
        "Combining the actual segmented images dataset and the generated images dataset to balance the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyKNOfuUHI4b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Define the paths to segmented and generated images folders\n",
        "segmented_images_folder = \"/content/drive/MyDrive/Project3/SegmentedImages\"\n",
        "generated_images_folder = \"/content/drive/MyDrive/Project3/GeneratedImages\"\n",
        "\n",
        "# Load segmented images\n",
        "segmented_images = []\n",
        "for image_file in os.listdir(segmented_images_folder):\n",
        "    image_path = os.path.join(segmented_images_folder, image_file)\n",
        "    image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
        "    image = image.resize((64, 64))  # Resize images to a consistent size\n",
        "    image_array = np.array(image) / 255.0  # Normalize pixel values\n",
        "    segmented_images.append(image_array)\n",
        "\n",
        "segmented_images = np.array(segmented_images)\n",
        "\n",
        "# Load generated non-tumorous images\n",
        "generated_images = []\n",
        "for image_file in os.listdir(generated_images_folder):\n",
        "    image_path = os.path.join(generated_images_folder, image_file)\n",
        "    image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
        "    image = image.resize((64, 64))  # Resize images to a consistent size\n",
        "    image_array = np.array(image) / 255.0  # Normalize pixel values\n",
        "    generated_images.append(image_array)\n",
        "\n",
        "generated_images = np.array(generated_images)\n",
        "\n",
        "# Combine the segmented and generated images\n",
        "combined_images = np.concatenate((segmented_images, generated_images), axis=0)\n",
        "\n",
        "# Shuffle the combined dataset to ensure randomness\n",
        "np.random.shuffle(combined_images)\n",
        "\n",
        "# Print the shape of the combined dataset\n",
        "print(\"Shape of combined dataset:\", combined_images.shape)\n",
        "# Now you can save the preprocessed images if needed\n",
        "output_folder = \"/content/drive/MyDrive/Project3/CombinedDataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A-QB0lQhNEI"
      },
      "source": [
        "## **VAE Model Building and VAE Model Training**\n",
        "Model Building and training the model on augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP9nfc34HJQk",
        "outputId": "00e1b5f8-1ded-4a4e-f7aa-bf26d44bbbd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 4s 500ms/step - loss: 0.2168\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.1878\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 3s 532ms/step - loss: 0.1853\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 4s 811ms/step - loss: 0.1851\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 3s 493ms/step - loss: 0.1848\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 2s 477ms/step - loss: 0.1839\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 3s 523ms/step - loss: 0.1840\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 3s 524ms/step - loss: 0.1829\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 4s 815ms/step - loss: 0.1778\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 3s 512ms/step - loss: 0.1621\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 3s 518ms/step - loss: 0.1449\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 3s 521ms/step - loss: 0.1347\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 0.1230\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 4s 779ms/step - loss: 0.1171\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 3s 581ms/step - loss: 0.0934\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 3s 510ms/step - loss: 0.0755\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.0668\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.0635\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 3s 653ms/step - loss: 0.0671\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 3s 655ms/step - loss: 0.0619\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.0602\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.0637\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.0632\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.0591\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 4s 730ms/step - loss: 0.0533\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 3s 549ms/step - loss: 0.0541\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 2s 500ms/step - loss: 0.0519\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 3s 501ms/step - loss: 0.0522\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 2s 494ms/step - loss: 0.0518\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 4s 750ms/step - loss: 0.0534\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 3s 517ms/step - loss: 0.0526\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.0496\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 3s 510ms/step - loss: 0.0517\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 2s 472ms/step - loss: 0.0645\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 4s 772ms/step - loss: 0.0557\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 3s 568ms/step - loss: 0.0510\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 2s 489ms/step - loss: 0.0575\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 2s 486ms/step - loss: 0.0505\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.0460\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 3s 680ms/step - loss: 0.0555\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 3s 659ms/step - loss: 0.0550\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 3s 540ms/step - loss: 0.0537\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.0510\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.0527\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 3s 620ms/step - loss: 0.0496\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 4s 695ms/step - loss: 0.0493\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 3s 521ms/step - loss: 0.0535\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.0498\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 2s 485ms/step - loss: 0.0493\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 3s 519ms/step - loss: 0.0542\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 4s 787ms/step - loss: 0.0530\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 3s 506ms/step - loss: 0.0486\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.0471\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 2s 471ms/step - loss: 0.0477\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 2s 484ms/step - loss: 0.0505\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 3s 735ms/step - loss: 0.0500\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 3s 546ms/step - loss: 0.0543\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 2s 503ms/step - loss: 0.0495\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 2s 487ms/step - loss: 0.0529\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.0517\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 3s 733ms/step - loss: 0.0508\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 3s 636ms/step - loss: 0.0576\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.0567\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 3s 552ms/step - loss: 0.0617\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 2s 488ms/step - loss: 0.0516\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 3s 655ms/step - loss: 0.0521\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 4s 723ms/step - loss: 0.0497\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 2s 496ms/step - loss: 0.0460\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 2s 468ms/step - loss: 0.0555\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 2s 470ms/step - loss: 0.0522\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 0.0558\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 4s 783ms/step - loss: 0.0523\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 2s 467ms/step - loss: 0.0569\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.0512\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 3s 491ms/step - loss: 0.0578\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 2s 480ms/step - loss: 0.0548\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 3s 740ms/step - loss: 0.0551\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 3s 588ms/step - loss: 0.0567\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 3s 510ms/step - loss: 0.0548\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 3s 523ms/step - loss: 0.0504\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 3s 512ms/step - loss: 0.0478\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 3s 738ms/step - loss: 0.0503\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 3s 616ms/step - loss: 0.0510\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 3s 518ms/step - loss: 0.0522\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 3s 492ms/step - loss: 0.0580\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 3s 512ms/step - loss: 0.0569\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 3s 703ms/step - loss: 0.0469\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 3s 631ms/step - loss: 0.0448\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 3s 517ms/step - loss: 0.0551\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 2s 474ms/step - loss: 0.0508\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 2s 478ms/step - loss: 0.0517\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 3s 566ms/step - loss: 0.0468\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 4s 726ms/step - loss: 0.0487\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 2s 479ms/step - loss: 0.0517\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 2s 476ms/step - loss: 0.0452\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 2s 481ms/step - loss: 0.0513\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 3s 521ms/step - loss: 0.0461\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 4s 786ms/step - loss: 0.0489\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 3s 482ms/step - loss: 0.0488\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 2s 482ms/step - loss: 0.0460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, optimizers\n",
        "\n",
        "# Define the VAE architecture\n",
        "latent_dim = 128\n",
        "input_shape = (64, 64, 1)  # Assuming this is the shape of your input images\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = layers.Input(shape=input_shape)\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu', strides=2, padding='same')(encoder_inputs)\n",
        "x = layers.Conv2D(128, (3, 3), activation='relu', strides=2, padding='same')(x)\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "# Reparameterization trick\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(tf.keras.backend.shape(z_mean)[0], latent_dim),\n",
        "                                              mean=0., stddev=1.)\n",
        "    return z_mean + tf.keras.backend.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = layers.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(8 * 8 * 128, activation='relu')(decoder_inputs)  # Adjust shape based on desired output shape\n",
        "x = layers.Reshape((8, 8, 128))(x)  # Adjust shape based on desired output shape\n",
        "x = layers.Conv2DTranspose(128, (3, 3), activation='relu', strides=2, padding='same')(x)\n",
        "x = layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same')(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Define the VAE model\n",
        "encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "decoder = models.Model(decoder_inputs, decoder_outputs, name='decoder')\n",
        "outputs = decoder(encoder(encoder_inputs)[2])\n",
        "vae = models.Model(encoder_inputs, outputs, name='vae')\n",
        "\n",
        "# Resize input images to match decoder output dimensions\n",
        "resized_inputs = tf.image.resize(encoder_inputs, (32, 32))\n",
        "\n",
        "# Define the loss function for VAE\n",
        "reconstruction_loss = losses.mean_squared_error(resized_inputs, outputs)\n",
        "kl_loss = -0.5 * tf.keras.backend.mean(1 + z_log_var - tf.keras.backend.square(z_mean) - tf.keras.backend.exp(z_log_var), axis=-1)\n",
        "vae_loss = tf.keras.backend.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "\n",
        "# Compile the VAE model\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "# Prepare the combined dataset\n",
        "combined_dataset = np.concatenate((segmented_images, generated_images), axis=0)\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "np.random.shuffle(combined_dataset)\n",
        "\n",
        "# Train the VAE model on the combined dataset\n",
        "vae.fit(combined_dataset, epochs=100, batch_size=32)\n",
        "\n",
        "# Save the trained VAE model\n",
        "vae.save(\"/content/drive/MyDrive/Project3/trained_vae_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbZpiWJsQ8iO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the trained VAE model\n",
        "vae = load_model(\"/content/drive/MyDrive/Project3/trained_vae_model.h5\")\n",
        "\n",
        "# Select a random image from the combined dataset\n",
        "random_index = np.random.randint(0, combined_images.shape[0])\n",
        "random_image = combined_images[random_index]\n",
        "\n",
        "# Reshape the image to match the model input shape if necessary\n",
        "# random_image = np.expand_dims(random_image, axis=0)  # Uncomment if needed\n",
        "\n",
        "# Generate prediction using the VAE model\n",
        "prediction = vae.predict(random_image.reshape(1, 64, 64, 1))\n",
        "\n",
        "# Plot the original image\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(random_image.squeeze(), cmap='gray')\n",
        "plt.title(\"Original Image\")\n",
        "\n",
        "# Plot the reconstructed image (prediction)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(prediction.squeeze(), cmap='gray')\n",
        "plt.title(\"Reconstructed Image\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxg81hPvMskp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Define the paths to segmented and generated images folders\n",
        "segmented_images_folder = \"/content/drive/MyDrive/Project3/SegmentedImages\"\n",
        "generated_images_folder = \"/content/drive/MyDrive/Project3/GeneratedImages\"\n",
        "combined_dataset_folder = \"/content/drive/MyDrive/Project3/CombinedDataset\"\n",
        "\n",
        "# Ensure the combined dataset folder exists, if not, create it\n",
        "if not os.path.exists(combined_dataset_folder):\n",
        "    os.makedirs(combined_dataset_folder)\n",
        "\n",
        "# Load segmented images\n",
        "segmented_images = []\n",
        "for image_file in os.listdir(segmented_images_folder):\n",
        "    image_path = os.path.join(segmented_images_folder, image_file)\n",
        "    image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
        "    image = image.resize((64, 64))  # Resize images to a consistent size\n",
        "    image_array = np.array(image) / 255.0  # Normalize pixel values\n",
        "    segmented_images.append(image_array)\n",
        "\n",
        "segmented_images = np.array(segmented_images)\n",
        "\n",
        "# Load generated non-tumorous images\n",
        "generated_images = []\n",
        "for image_file in os.listdir(generated_images_folder):\n",
        "    image_path = os.path.join(generated_images_folder, image_file)\n",
        "    image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
        "    image = image.resize((64, 64))  # Resize images to a consistent size\n",
        "    image_array = np.array(image) / 255.0  # Normalize pixel values\n",
        "    generated_images.append(image_array)\n",
        "\n",
        "generated_images = np.array(generated_images)\n",
        "\n",
        "# Combine the segmented and generated images\n",
        "combined_images = np.concatenate((segmented_images, generated_images), axis=0)\n",
        "\n",
        "# Shuffle the combined dataset to ensure randomness\n",
        "np.random.shuffle(combined_images)\n",
        "\n",
        "# Save the combined dataset images in the CombinedDataset folder\n",
        "for i, image in enumerate(combined_images):\n",
        "    image_save_path = os.path.join(combined_dataset_folder, f\"combined_image_{i}.png\")\n",
        "    image = (image * 255).astype(np.uint8)  # Convert back to uint8 before saving\n",
        "    Image.fromarray(image).save(image_save_path)\n",
        "\n",
        "print(\"Combined dataset images saved in folder:\", combined_dataset_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKE6RewsHuyy",
        "outputId": "725dd100-3338-4c16-d054-73079ddefcaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 347ms/step\n",
            "Average Intensity: 0.84198576\n",
            "Variance: 0.02193873\n",
            "Tumorous image detected.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.keras import models\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Function to generate Grad-CAM heatmap\n",
        "def generate_grad_cam(model, img_array, layer_name):\n",
        "    # Convert the NumPy array to a TensorFlow tensor\n",
        "    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)\n",
        "\n",
        "    # Get the model prediction\n",
        "    preds = model.predict(img_tensor)\n",
        "    class_idx = np.argmax(preds[0])\n",
        "\n",
        "    # Get the output of the last convolutional layer\n",
        "    last_conv_layer = model.get_layer(layer_name)\n",
        "    last_conv_layer_model = models.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Compute gradients of the predicted class with regard to the output feature map of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output = last_conv_layer_model(img_tensor)\n",
        "        target_class_output = last_conv_layer_output[:, class_idx]\n",
        "    grads = tape.gradient(target_class_output, last_conv_layer_output)\n",
        "\n",
        "    # Compute the importance of each feature map\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = tf.reduce_mean(last_conv_layer_output * pooled_grads[..., tf.newaxis], axis=-1)\n",
        "\n",
        "    # Normalize the heatmap\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def detect_tumors(image, image_path, vae_model):\n",
        "    # Load the image\n",
        "    img = Image.open(image_path)\n",
        "    img = img.convert('L')  # Convert to grayscale\n",
        "    img = img.resize((64, 64))  # Resize the image to match the VAE input size\n",
        "\n",
        "    # Convert image to numpy array and normalize\n",
        "    img_array = np.array(img) / 255.0  # Normalize pixel values\n",
        "    img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Reconstruct the image and compute reconstruction error\n",
        "    reconstructed_image = vae_model.predict(img_array)\n",
        "    reconstructed_image = reconstructed_image.squeeze(axis=0)  # Remove batch dimension\n",
        "\n",
        "    # Compute features indicative of tumors\n",
        "    average_intensity = np.mean(reconstructed_image)\n",
        "    variance = np.var(reconstructed_image)\n",
        "    print(\"Average Intensity:\", average_intensity)\n",
        "    print(\"Variance:\", variance)\n",
        "\n",
        "    intensity_threshold_tumor = 0.25\n",
        "    variance_threshold_tumor = 0.05\n",
        "\n",
        "            # Adjusted thresholds for non-tumor classification\n",
        "    intensity_threshold_non_tumor = 0.2\n",
        "    variance_threshold_non_tumor = 0.03\n",
        "\n",
        "    if average_intensity > intensity_threshold_tumor and variance > variance_threshold_tumor:\n",
        "            return \"Tumorous image detected.\"\n",
        "    elif average_intensity < intensity_threshold_non_tumor and variance < variance_threshold_non_tumor:\n",
        "                return \"Non-tumorous image detected.\"\n",
        "\n",
        "# Load the trained VAE model\n",
        "vae_model = models.load_model(\"/content/drive/MyDrive/Project3/trained_vae_model.h5\")\n",
        "\n",
        "# Load the combined dataset folder\n",
        "combined_dataset_folder = \"/content/drive/MyDrive/Project3/CombinedDataset\"\n",
        "\n",
        "# Randomly select an image from the combined dataset for testing\n",
        "random_image_name = np.random.choice(os.listdir(combined_dataset_folder))\n",
        "random_image_path = os.path.join(combined_dataset_folder, random_image_name)\n",
        "random_image = np.array(Image.open(random_image_path))\n",
        "\n",
        "# Detect tumors in the randomly selected image\n",
        "detect_tumors(random_image, random_image_path, vae_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "wHW5vql19ucY",
        "outputId": "1c4e1f96-703c-4c01-ab2b-4687260872c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 214ms/step\n",
            "Normalized Average Intensity: 3.066101471583049\n",
            "Normalized Variance: 0.15391224063932896\n",
            "Tumorous image detected.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def detect_tumors(image, image_path, vae_model):\n",
        "    # Load the image\n",
        "    img = Image.open(image_path)\n",
        "    img = img.convert('L')  # Convert to grayscale\n",
        "    img = img.resize((64, 64))  # Resize the image to match the VAE input size\n",
        "\n",
        "    # Convert image to numpy array and normalize\n",
        "    img_array = np.array(img) / 255.0  # Normalize pixel values\n",
        "    img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Reconstruct the image and compute reconstruction error\n",
        "    reconstructed_image = vae_model.predict(img_array)\n",
        "    reconstructed_image = reconstructed_image.squeeze(axis=0)  # Remove batch dimension\n",
        "\n",
        "    # Compute features indicative of tumors\n",
        "    average_intensity = np.mean(reconstructed_image)\n",
        "    variance = np.var(reconstructed_image)\n",
        "\n",
        "    # Normalize the variables\n",
        "    average_intensity /= 0.3  # Scale to range [0, 1]\n",
        "    variance /= 0.1  # Scale to range [0, 1]\n",
        "\n",
        "    print(\"Normalized Average Intensity:\", average_intensity)\n",
        "    print(\"Normalized Variance:\", variance)\n",
        "\n",
        "    intensity_threshold_tumor = 0.25\n",
        "    variance_threshold_tumor = 0.05\n",
        "\n",
        "    # Adjusted thresholds for non-tumor classification\n",
        "    intensity_threshold_non_tumor = 0.2\n",
        "    variance_threshold_non_tumor = 0.03\n",
        "\n",
        "    if average_intensity > intensity_threshold_tumor and variance > variance_threshold_tumor:\n",
        "            return \"Tumorous image detected.\"\n",
        "    elif average_intensity < intensity_threshold_non_tumor and variance < variance_threshold_non_tumor:\n",
        "            return \"Non-tumorous image detected.\"\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Load the trained VAE model\n",
        "vae_model = models.load_model(\"/content/drive/MyDrive/Project3/trained_vae_model.h5\")\n",
        "\n",
        "# Load the combined dataset folder\n",
        "combined_dataset_folder = \"/content/drive/MyDrive/Project3/CombinedDataset\"\n",
        "\n",
        "# Randomly select an image from the combined dataset for testing\n",
        "random_image_name = np.random.choice(os.listdir(combined_dataset_folder))\n",
        "random_image_path = os.path.join(combined_dataset_folder, random_image_name)\n",
        "random_image = np.array(Image.open(random_image_path))\n",
        "\n",
        "# Detect tumors in the randomly selected image\n",
        "detect_tumors(random_image, random_image_path, vae_model)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
